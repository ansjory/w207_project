{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project: House Prices Prediction\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques  \n",
    "\n",
    "### Team MLAIRE: Chi Iong Ansjory, Prabhat Tripathi, Soodong Kim, Tina Agarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to predict sale price of residential homes in Ames, Iowa based on the given training and test data sets. There are 79 explanatory variables describing different aspects of residential homes with 1460 observations in both training and test data sets (this is different than previous class projects where train data is usually larger than test data set). \n",
    "\n",
    "The output variable (SalePrice) is quantitative (continuous) whereas the explanatory (LHS) variables are a combination of quantitative (continuous) and categorical variables. \n",
    "\n",
    "Considering the size and nature of the data set, and informed by our domain understanding, we believe that *feature engineering* -- crafting data features optimized for machine learning -- is key for better modeling for this problem. Specifically, we plan to perform following:\n",
    "\n",
    "- Univariate analysis of output and explanatory variables: weed out spurious or wrong values. Understand patterns and outliers for each variable. Allow for missing values (NaN) imputations.\n",
    "- Transform categorical variables into numeric (using dummy variables?)\n",
    "- Check if log transformation of output and explanatory variables helps better model performance\n",
    "- Through bivariate analysis, identify and remove unhelpful explanatory variables (using correlation matrix or using techniques such as LASSO) and multicollinearity (if present)\n",
    "- Advance feature engineering techniques such as PCA?\n",
    "\n",
    "We also have to watch out for overfitting considering there are a large number of input variables (compared to the training data size).\n",
    "\n",
    "We plan to begin with (multiple) LinearRegression model (for speed) and if the accuracy is not satisfactory, we would try other models such as random forest and gradient-boosting tree. If needed, we may have to ensemble all these models for better overall accuracy. We will split test data into two random sets and use one as \"dev\" data during model building process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import necessary libraries such as sklearn, scipy, pandas, numpy, and seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each plot will not open a new window. \n",
    "# required libraries\n",
    "## pandas\n",
    "## seaborn\n",
    "%matplotlib inline\n",
    "\n",
    "# Import relevant libraries.\n",
    "\n",
    "# General libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SK-learn libraries for Projection/learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Sk-Learn libraries for data mangling.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "# Libraries for files\n",
    "import os\n",
    "\n",
    "# Python fundamental libraries\n",
    "import collections\n",
    "\n",
    "# Disable warnings for more clear output\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "\n",
    "Import both train and test data from csv files, make copies of both, and display the origin shapes of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes of train and test datasets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Please keep this relative path access to data.\n",
    "dir_name = os.getcwd()\n",
    "train_filename = os.path.join(dir_name, 'data/train.csv')\n",
    "test_filename = os.path.join(dir_name, 'data/test.csv')\n",
    "\n",
    "# Reading the data\n",
    "train = pd.read_csv(train_filename)\n",
    "test  = pd.read_csv(test_filename)\n",
    "\n",
    "print(\"Original shapes of train and test datasets:\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we summarize the train dataset features:  \n",
    "* Categorize 80 features into numerical, categorical. Among numerical features, distinguish \"discrete\" values features\n",
    "* Print a summary of numerical features with info such as: mean, min, max, number of NaNs, isDiscrete\n",
    "* Print a summary of categorical features with info such as: number of NaNs, number of distinct values\n",
    "* Print a summary on whether the features are selected or not based on following analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions of variables are based on https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data. Variable types are either categorical, or discrete/non-discrete numeric. There are 4 different \"Segments\": Sale (sales transaction of house), Location (where the house located), Building (physical characteristics), Space (space properties of house). For numerical variables, mean, min, max, and number of NaNs are derived from descriptive statistics, and also determine if it is discrete from the histogram. For categorical variables, number of NaNs and distinct values are determined by histogram. There are 3 levels of \"Expectations\": High, Medium, and Low of how the variables are related to the sale price. Column \"Selected\" indicates if the variables are included in the model based on the following analysis.\n",
    "\n",
    "| ID | Variable | Description | Segment | Type | Discrete | Mean | Min | Max | NaN | Distinct Value | Expectation | Selected |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | SalePrice | Property's sale price in dollars | Building | Numeric | No | 180921 | 34900 | 755000 | 0 | | Explantory Variable | Yes |\n",
    "| 2 | MSSubClass | Building class | Building | Categorical | | | | | 0 | 15 | Low | No |\n",
    "| 3 | MSZoning | General zoning classification | Building | Categorical | | | | | 0 | 5  | Low | No |\n",
    "| 4 | LotFrontage | Linear feet of street connected to property | Space | Numeric | No | 70 | 21 | 313 | 259 | | Medium | No |\n",
    "| 5 | LotArea | Lot size in square feet | Space | Numeric | No | 10516 | 1300 | 215245 | 0 | | High | No |\n",
    "| 6 | Street | Type of road access | Location | Categorical | | | | | 0 | 2 | Low | No |\n",
    "| 7 | Alley | Type of alley access | Location | Categorical | | | | | rename needed on NA (No alley access) | 3 | Low | No |\n",
    "| 8 | LotShape | General shape of property | Location | Categorical | | | | | 0 | 4 | Low | No |\n",
    "| 9 | LandContour | Flatness of the property | Location | Categorical | | | | | 0 | 9 | Low | No |\n",
    "| 10 | Utilities | Type of utilities available | Location | Categorical | | | | | 0 | 1 | Low | No |\n",
    "| 11 | LotConfig | Lot configuration | Location | Categorical | | | | | 0 | 5 | Medium | No |\n",
    "| 12 | LandSlope | Slope of property | Location | Categorical | | | | | 0 | 3 | Low | No |\n",
    "| 13 | Neighborhood | Physical locations within Ames city limits | Location | Categorical | | | | | 0 | 25 | Medium | No |\n",
    "| 14 | Condition1 | Proximity to main road or railroad | Location | Categorical | | | | | 0 | 9 | Medium | No |\n",
    "| 15 | Condition2 | Proximity to main road or railroad (if a second is present) | Location | Categorical | | | | | 0 | 2| Low | No |\n",
    "| 16 | BldgType | Type of dwelling | Building | Categorical | | | | | 0 | 5 | Low | No |\n",
    "| 17 | HouseStyle | Style of dwelling | Building | Categorical | | | | | 0 | 8 | Low | No |\n",
    "| 18 | OverallQual | Overall material and finish quality | Building | Numeric | Yes | 6 | 1 | 10 | 0 | | High | Yes |\n",
    "| 19 | OverallCond | Overall condition rating | Building | Numeric | Yes | 5 | 1 | 9 | 0 | | Medium | No |\n",
    "| 20 | YearBuilt | Original construction date | Building | Categorical | | | | | 0 | 112 | High | Yes |\n",
    "| 21 | YearRemodAdd | Remodel date | Building | Categorical | | | | | 0 | 61 | High | Yes |\n",
    "| 22 | RoofStyle | Type of roof | Building | Categorical | | | | | 0 | 5 | Medium | No |\n",
    "| 23 | RoofMatl | Roof material | Building | Categorical | | | | | 0 | 4 | Low | No |\n",
    "| 24 | Exterior1st | Exterior covering on house | Building | Categorical | | | | | 0 | 12 | Medium | No |\n",
    "| 25 | Exterior2nd | Exterior covering on house (if more than one material) | Building | Categorical | | | | | 0 | 16| Low | No |\n",
    "| 26 | MasVnrType | Masonry veneer type | Building | Categorical | | | | | 0 | 4 | Low | No |\n",
    "| 27 | MasVnrArea | Masonry veneer area in square feet | Space | Numeric | No | 103 | 0 | 1600 | 8 | 0 | Low | No |\n",
    "| 28 | ExterQual | Exterior material quality | Building | Categorical | | | | | 0 | 4 | Low | No |\n",
    "| 29 | ExterCond | Present condition of the material on the exterior | Building | Categorical | | | | | 0 | 3 | Medium  | No |\n",
    "| 30 | Foundation | Type of foundation | Building | Categorical | | | | | 0 | 6 | Low | No |\n",
    "| 31 | BsmtQual | Evaluates the height of the basement | Building | Categorical | | | | | 0 | 4 | Low | No |\n",
    "| 32 | BsmtCond | General condition of the basement | Building | Categorical | | | | | 0 | 3 | Medium | No |\n",
    "| 33 | BsmtExposure | Walkout or garden level basement walls | Building | Categorical | | | | | 0 | 4 | Low | No |\n",
    "| 34 | BsmtFinType1 | Quality of basement finished area | Building | Categorical | | | | | 0 | 6 | Low | No |\n",
    "| 35 | BsmtFinSF1 | Type 1 finished square feet | Space | Numeric | No | 443 | 0 | 5644 | 0 | | Medium | No |\n",
    "| 36 | BsmtFinType2 | Quality of second finished area (if present) | Building | Categorical | | | | | 0 | 6 | Low | No |\n",
    "| 37 | BsmtFinSF2 | Type 2 finished square feet | Space | Numeric | No | 46 | 0 | 1474 | 0 | | Low | No |\n",
    "| 38 | BsmtUnfSF | Unfinished square feet of basement area | Space | Numeric | No | 567 | 0 | 2336 | 0 | | Medium | No |\n",
    "| 39 | TotalBsmtSF | Total square feet of basement area | Space | Numeric | No | 1057 | 0 | 6110 | 0 | | High | Yes |\n",
    "| 40 | Heating | Type of heating | Building | Categorical | | | | | 0 | 3 | Low | No |\n",
    "| 41 | HeatingQC | Heating quality and condition | Building | Categorical | | | | | 0 | 5 | Low | No |\n",
    "| 42 | CentralAir | Central air conditioning | Building | Categorical | | | | | 0 | 2 | Medium | No |\n",
    "| 43 | Electrical | Electrical system | Building | Categorical | | | | | 1 | 5 | Low | No |\n",
    "| 44 | 1stFlrSF | First Floor square feet | Space | Numeric | No | 1162 | 334 | 4692 | 0 | | High | Yes |\n",
    "| 45 | 2ndFlrSF | Second floor square feet | Space | Numeric | No | 346 | 0 | 2065 | 0 | | Medium | No |\n",
    "| 46 | LowQualFinSF | Low quality finished square feet (all floors) | Space | Numeric | No | 5 | 0 | 572 | 0 | | Low | No |\n",
    "| 47 | GrLivArea | Above grade (ground) living area square feet | Space | Numeric | No | 1515 | 334 | 5642 | 0 | | High | Yes |\n",
    "| 48 | BsmtFullBath | Basement full bathrooms | Building | Numeric | Yes | 0 | 0 | 3 | 0 | | Low | No |\n",
    "| 49 | BsmtHalfBath | Basement half bathrooms | Building | Numeric | Yes | 0 | 0 | 2 | 0 | | Low | No |\n",
    "| 50 | FullBath | Full bathrooms above grade | Building | Numeric | Yes | 1 | 0 | 3 | 0 | | High | Yes |\n",
    "| 51 | HalfBath | Half baths above grade | Building | Numeric | Yes | 0 | 0 | 2 | 0 | | Low | No |\n",
    "| 52 | BedroomAbvGr | Number of bedrooms above basement level | Building | Numeric | Yes | 2 | 0 | 8 | 0 | | Medium | No |\n",
    "| 53 | KitchenAbvGr | Number of kitchens | Building | Numeric | Yes | 1 | 0 | 3 | 0 | | Low | No |\n",
    "| 54 | KitchenQual | Kitchen quality | Building | Categorical | | | | | 0 | 4 | Medium | No |\n",
    "| 55 | TotRmsAbvGrd | Total rooms above grade (does not include bathrooms) | Building | Numeric | Yes | 6 | 2 | 14 | 0 | | High | Yes |\n",
    "| 56 | Functional | Home functionality rating | Building | Categorical | | | | | 0 | 7 | Low | No |\n",
    "| 57 | Fireplaces | Number of fireplaces | Building | Numeric | Yes | 0 | 0 | 3 | 0 | | Medium | No |\n",
    "| 58 | FireplaceQu | Fireplace quality | Building | Categorical | | | | | 690 | 5 | Low | No |\n",
    "| 59 | GarageType | Garage location | Building | Categorical | | | | | 81 | 6 | Low | No |\n",
    "| 60 | GarageYrBlt | Year garage was built | Building | Categorical | | | | | 81 | 97 | Low | No |\n",
    "| 61 | GarageFinish | Interior finish of the garage | Building | Categorical | | | | | 81 | 3 | Low | No |\n",
    "| 62 | GarageCars | Size of garage in car capacity | Building | Numeric | Yes | 1 | 0 | 4 | 0 | | High | Yes |\n",
    "| 63 | GarageArea | Size of garage in square feet | Space | Numeric | No | 472 | 0 | 1418 | 0 | | High | Yes |\n",
    "| 64 | GarageQual | Garage quality | Building | Categorical | | | | | 81 | 5 | Low | No |\n",
    "| 65 | GarageCond | Garage condition | Building | Categorical | | | | | 81 | 5 | Low | No |\n",
    "| 66 | PavedDrive | Paved driveway | Building | Categorical | | | | | 0 | 3 | Medium | No |\n",
    "| 67 | WoodDeckSF | Wood deck area in square feet | Space | Numeric | No | 94 | 0 | 857 | 0 | | Low | No |\n",
    "| 68 | OpenPorchSF | Open porch area in square feet | Space | Numeric | No | 46 | 0 | 547 | 0 | | Low | No |\n",
    "| 69 | EnclosedPorch | Enclosed porch area in square feet | Space | Numeric | No | 21 | 0 | 552 | 0 | | Low | No |\n",
    "| 70 | 3SsnPorch | Three season porch area in square feet | Space | Numeric | No | 3 | 0 | 508 | 0 | | Low | No |\n",
    "| 71 | ScreenPorch | Screen porch area in square feet | Space | Numeric | No | 15 | 0 | 480 | 0 | | Low | No |\n",
    "| 72 | PoolArea | Pool area in square feet | Space | Numeric | No | 2 | 0 | 738 | 0 | | Medium | No |\n",
    "| 73 | PoolQC | Pool quality | Building | Categorical | | | | | 1453 | 3 | Low | No |\n",
    "| 74 | Fence | Fence quality | Building | Categorical | | | | | 1179 | 4 | Low | No |\n",
    "| 75 | MiscFeature | Miscellaneous feature not covered in other categories | Building | Categorical | | | | | 1406 | 4 | Low | No |\n",
    "| 76 | MiscVal | $Value of miscellaneous feature | Building | Numeric | No | 43 | 0 | 15500 | 0 | | Low | No |\n",
    "| 77 | MoSold | Month Sold | Sale | Categorical | | | | | 0 | 12 | Medium | No |\n",
    "| 78 | YrSold | Year Sold | Sale | Categorical | | | | | 0 | 5 | Medium | No |\n",
    "| 79 | SaleType | Type of sale | Sale | Categorical | | | | | 0 | 9 | Medium | No |\n",
    "| 80 | SaleCondition | Condition of sale | Sale | Categorical | | | | | 0 | 6 | Medium | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance of the train dataset with 5 rows and 81 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance of the 80 variables excluding 'Id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify 15-20 interesting features and perform their data analysis\n",
    "* SalePrice\n",
    "* numeric feature\n",
    "* discrete feature\n",
    "* categorical feature\n",
    "\n",
    "We can use plots such as Histogram, boxplot to understand their distribution and general structure of these features\n",
    "* note outliers\n",
    "* note if some transformation of a feature would help\n",
    "* practical and statistical significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Target Variable Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Description\n",
    "train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram and normal probability plot\n",
    "sns.distplot(train['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Kurtosis\n",
    "print(\"Skewness: \", train['SalePrice'].skew())\n",
    "print(\"Kurtosis: \", train['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the target variable SalePrice has a right-skewed distribution. We'll need to log transform this variable so that it becomes normally distributed. A normally distributed target variable helps in better modeling the relationship between target and independent variables. Alternatively, we can also confirm this skewed behavior using the skewness metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying log transformation\n",
    "sns.distplot(np.log(train['SalePrice']), fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above log transformation of the target variable has helped us fixing its skewed distribution and the new distribution looks closer to normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis for numeric variable *GrLivArea* as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "train['GrLivArea'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GrLivArea* is  normal based on the histogram and normal probabilty plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram and normal probability plot\n",
    "sns.distplot(train['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis for discrete variable *OverallQual* as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "train['OverallQual'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['OverallQual']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis for categorical variable *YearBuilt* as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['YearBuilt']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted in descending order\n",
    "train['YearBuilt'].value_counts().plot(kind='bar', figsize=(20,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find correlation between SalePrice and a set of important identified features (10-15) and plot their correlation matrix. \n",
    "\n",
    "Since Id is irrelevant column, it will be dropped. The correlation matrix show evidence of multicollearity. Let's begin with the focus on those 10 variables which are highly correlated to *SalePrice*, which are *OverallQual*, *YearBuilt*, *YearRemodAdd*, *TotalBsmtSF*, *1stFlrSF*, *GrLivArea*, *FullBath*, *TotRmsAbvGrd*, *GarageCars*, and *GarageArea*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix showing evidence of multicollearity\n",
    "# Remove Id column which is totally irrlevant\n",
    "copied_train = train.drop(['Id'], axis=1, errors='raise')\n",
    "corrmat = copied_train.corr()\n",
    "mask = np.zeros_like(corrmat)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, mask=mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at some variables based on their correlation with the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = copied_train.corr()\n",
    "print (corr_matrix['SalePrice'].sort_values(ascending=False)[:15], '\\n') #top 15 values\n",
    "print ('----------------------')\n",
    "print (corr_matrix['SalePrice'].sort_values(ascending=False)[-5:]) #last 5 values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some variables seem to be strongly correlated with the target variable. Here we see that the OverallQual feature is 79% correlated with the target variable. Overallqual feature Rates the overall material and finish of the house. This seems to be the parameter that affects the sale price positively. In addition, GrLivArea is 70% correlated with the target variable. GrLivArea refers to the living area (in sq ft.) above ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saleprice correlation matrix\n",
    "k = 10 # number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(copied_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f',\n",
    "                 annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For relationship with numeric feature, such as *SalePrice* and *TotalBsmtSF*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "var = 'TotalBsmtSF'\n",
    "copied_train[var].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TotalBsmt* has close to normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram and normal probability plot\n",
    "sns.distplot(copied_train[var], fit=norm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GrLivArea* and *SalePrice* seem to have linear relationship of larger the area, higher the price. However, there are observable outliers on the higher extremes of areas. Also, the conic shape demostrates homoscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of totalbsmtsf/saleprice\n",
    "data = pd.concat([train['SalePrice'], copied_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logaritham transformation could allevate the problem of homoscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot after log transformation showing allevation of homoscedasticity problem\n",
    "plt.scatter(np.log(copied_train[var]), np.log(train['SalePrice']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For relationship with categorical features, such as *OverallQual* and *SalePrice*, *YearBuilt* and *SalePrice*):\n",
    "\n",
    "The boxplot shows that there is a linearly relationship between quality and price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot overallqual/saleprice\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([train['SalePrice'], copied_train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot also shows the general trend of higher price for newer house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot yearbuilt/saleprice\n",
    "var = 'YearBuilt'\n",
    "data = pd.concat([train['SalePrice'], copied_train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For relationship with discrete features, such as *GarageCars* and *SalePrice*:\n",
    "\n",
    "The boxplot shows that there is linear relationship between size of garage and price when garage size is between 0 and 3. House with 4-car garage doesn't follow the relationship of higher price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot garagecars/saleprice\n",
    "var = 'GarageCars'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatterplot of *SalePrice* vs the 10 picked variables, look like all demonstrate linear relationship with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF',\n",
    "        '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea']\n",
    "sns.pairplot(copied_train[cols], size=2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we decided to check how many missing values are existing for each column. Since mssing values can mislead prediction, analysis is necessary. Please note that data mangling or data transformation will be covered by the other section (Feature Engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Number of Missing Data</th>\n",
       "      <th>Missing Data Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total Number of Missing Data  Missing Data Percentage\n",
       "PoolQC                                1453                99.520548\n",
       "MiscFeature                           1406                96.301370\n",
       "Alley                                 1369                93.767123\n",
       "Fence                                 1179                80.753425\n",
       "FireplaceQu                            690                47.260274\n",
       "LotFrontage                            259                17.739726\n",
       "GarageCond                              81                 5.547945\n",
       "GarageType                              81                 5.547945\n",
       "GarageYrBlt                             81                 5.547945\n",
       "GarageFinish                            81                 5.547945\n",
       "GarageQual                              81                 5.547945\n",
       "BsmtExposure                            38                 2.602740\n",
       "BsmtFinType2                            38                 2.602740\n",
       "BsmtFinType1                            37                 2.534247\n",
       "BsmtCond                                37                 2.534247\n",
       "BsmtQual                                37                 2.534247\n",
       "MasVnrArea                               8                 0.547945\n",
       "MasVnrType                               8                 0.547945\n",
       "Electrical                               1                 0.068493\n",
       "Utilities                                0                 0.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate about missing data.\n",
    "# Analyze top 20 columns having missing data.\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum() / train.isnull().count() * 100).sort_values(ascending=False)\n",
    "missing_data = pd.concat(\n",
    "    [total, percent], axis=1, keys=[\"Total Number of Missing Data\", \"Missing Data Percentage\"])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Drop columns with 80% missing data since filling default data for 80% makes this column to be skewed. <br>\n",
    "2) Also drop the 'Id' column which is irrelevant to model. <br>\n",
    "3) In addition to 'Id', 'LotFrontage' column will not be used since defining default value for linear feat is not feasible.<br>\n",
    "4) Columns not dropped will be re-visited in the follow-up section 'Feature Engineering'. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_will_be_removed = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id', 'LotFrontage']\n",
    "\n",
    "train.drop(columns_will_be_removed, axis=1, inplace=True, errors='ignore')\n",
    "test.drop(columns_will_be_removed, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Double check whether above columns are removed\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum() / train.isnull().count() * 100).sort_values(ascending=False)\n",
    "assert percent[0] < 50.0\n",
    "\n",
    "def assert_column_drop(data, col_names):\n",
    "    for col_name in col_names:\n",
    "        assert col_name not in data, \"%s should not exist\" % col_name\n",
    "\n",
    "assert_column_drop(train, ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id', 'LotFrontage'])\n",
    "assert_column_drop(test, ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id', 'LotFrontage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train after removing columns with 80% missing data: (1460, 75)\n",
      "Shape of test after removing columns with 80% missing data: (1459, 74)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train after removing columns with 80% missing data: {}\".format(train.shape))\n",
    "print(\"Shape of test after removing columns with 80% missing data: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing Values\n",
    "\n",
    "1) For string data columns, default value can be guessed from the documnation. <br>\n",
    "2) For non string data columns, zero can be assigned. Although zero can mislead prediction, there will be another step for data binning that is reducing effects of minor observation errors. That is, it can justify filling missing value with zero. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values for string data column\n",
      "Filling missing values for non-string data (numeric, categorical) column\n"
     ]
    }
   ],
   "source": [
    "print(\"Filling missing values for string data column\")\n",
    "train['FireplaceQu'] = train['FireplaceQu'].fillna('None')\n",
    "train['GarageCond'] = train['GarageCond'].fillna('None') # Garage conditon should be None\n",
    "train['GarageType'] = train['GarageType'].fillna('None') # Garage Type should be None\n",
    "train['GarageFinish'] = train['GarageFinish'].fillna('None') # Garage Finish should be None\n",
    "train['GarageQual'] = train['GarageQual'].fillna('None') # Garage Qual should be None\n",
    "train['BsmtCond'] = train['BsmtCond'].fillna('None')  # Basement condition should be None\n",
    "train['BsmtFinType1'] = train['BsmtFinType1'].fillna('None') #should be None\n",
    "train['BsmtQual'] = train['BsmtQual'].fillna('None') #should be None\n",
    "train['BsmtFinType2'] = train['BsmtFinType2'].fillna('None') #should be None\n",
    "train['BsmtExposure'] = train['BsmtExposure'].fillna('None') #should be None\n",
    "train[\"Functional\"] = train[\"Functional\"].fillna(\"Typ\")\n",
    "train['MasVnrType'] = train['MasVnrType'].fillna('None')\n",
    "\n",
    "test['FireplaceQu'] = test['FireplaceQu'].fillna('None')\n",
    "test['GarageCond'] = test['GarageCond'].fillna('No Garage')\n",
    "test['GarageType'] = test['GarageType'].fillna('No Garage')\n",
    "test['GarageFinish'] = test['GarageFinish'].fillna('No Garage')\n",
    "test['GarageQual'] = test['GarageQual'].fillna('No Garage')\n",
    "test['BsmtCond'] = test['BsmtCond'].fillna('No Basement')\n",
    "test['BsmtFinType1'] = test['BsmtFinType1'].fillna('No Basement')\n",
    "test['BsmtQual'] = test['BsmtQual'].fillna('No Basement')\n",
    "test['BsmtFinType2'] = test['BsmtFinType2'].fillna('No Basement')\n",
    "test['BsmtExposure'] = test['BsmtExposure'].fillna('No Basement')\n",
    "test[\"Functional\"] = test[\"Functional\"].fillna(\"Typ\")\n",
    "test['MasVnrType'] = test['MasVnrType'].fillna('None')\n",
    "\n",
    "print(\"Filling missing values for non-string data (numeric, categorical) column\")\n",
    "train['BsmtHalfBath'] = train['BsmtHalfBath'].fillna(0)\n",
    "train['BsmtFullBath'] = train['BsmtFullBath'].fillna(0)\n",
    "train['GarageCars'] = train['GarageCars'].fillna(0)\n",
    "train['GarageArea'] = train['GarageArea'].fillna(0)\n",
    "train['TotalBsmtSF'] = train['TotalBsmtSF'].fillna(0)\n",
    "train['BsmtFinSF1'] = train['BsmtFinSF1'].fillna(0)\n",
    "train['BsmtFinSF1'] = train['BsmtFinSF1'].fillna(0)\n",
    "train['BsmtUnfSF'] = train['BsmtUnfSF'].fillna(0)\n",
    "train['MSZoning'] = train['MSZoning'].fillna(train['MSZoning'].mode()[0]) #RL\n",
    "train['KitchenQual'] = train['KitchenQual'].fillna(train['KitchenQual'].mode()[0]) #TA\n",
    "train['Exterior1st'] = train['Exterior1st'].fillna(train['Exterior1st'].mode()[0]) #other\n",
    "train['Exterior2nd'] = train['Exterior2nd'].fillna(train['Exterior2nd'].mode()[0]) #other\n",
    "train['SaleType'] = train['SaleType'].fillna(train['SaleType'].mode()[0]) #oth\n",
    "train['Electrical'] = train['Electrical'].fillna(train['Electrical'].mode()[0])\n",
    "train['MasVnrArea'] = train['MasVnrArea'].fillna(0)\n",
    "train['GarageYrBlt'] = train['GarageYrBlt'].fillna('0')\n",
    "\n",
    "test['BsmtHalfBath'] = test['BsmtHalfBath'].fillna(0)\n",
    "test['BsmtFullBath'] = test['BsmtFullBath'].fillna(0)\n",
    "test['GarageCars'] = test['GarageCars'].fillna(0)\n",
    "test['GarageArea'] = test['GarageArea'].fillna(0)\n",
    "test['TotalBsmtSF'] = test['TotalBsmtSF'].fillna(0)\n",
    "test['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(0)\n",
    "test['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(0)\n",
    "test['BsmtUnfSF'] = test['BsmtUnfSF'].fillna(0)\n",
    "test['MSZoning'] = test['MSZoning'].fillna(train['MSZoning'].mode()[0]) #RL\n",
    "test['KitchenQual'] = test['KitchenQual'].fillna(train['KitchenQual'].mode()[0]) #TA\n",
    "test['Exterior1st'] = test['Exterior1st'].fillna(train['Exterior1st'].mode()[0])\n",
    "test['Exterior2nd'] = test['Exterior2nd'].fillna(train['Exterior2nd'].mode()[0])\n",
    "test['SaleType'] = test['SaleType'].fillna(train['SaleType'].mode()[0])\n",
    "test['Electrical'] = test['Electrical'].fillna(train['Electrical'].mode()[0])\n",
    "test['MasVnrArea'] = test['MasVnrArea'].fillna(0)\n",
    "test['GarageYrBlt'] = test['GarageYrBlt'].fillna('0')\n",
    "\n",
    "# Missing values re-check after filling data\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum() / train.isnull().count() * 100).sort_values(ascending=False)\n",
    "assert percent[0] <= 0.00, \"There is still %r missing values\" % (total[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) To reduce side impact of filled data with default value, we dediced to bin year data into pre 1950, 1950 - 1974, 1975 - 2000, and post 2000 respectively. By this approach, if deafult value is filled by zero, it will be categorized in to pre-1950 instead of recognizing data itself as zero. We can assume that if data is missed, house data may not be recorded properly since it was built or remodeled before 1950.<br>\n",
    "2) After binning, the targer column having continuous int value will be dropped.<br>\n",
    "3) As a final step, value will be transformed into discrete value such as 1, 2, 3, or 4. Since recent update on the property can have a positive impact, larger value assigning for the recent years can be justfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageBlt column values: 1,2,3,4\n",
      "YrRemodeled column values: 2,3,4\n",
      "YrBuilt column values: 1,2,4\n"
     ]
    }
   ],
   "source": [
    "PERIOD_TO_VALUE = {'0': 0, 'Before1950': 1, '1950to1974': 2, '1975to1999': 3, '2000OrLater': 4}\n",
    "# Data Binning\n",
    "# GarageYrBlt -> GarageBlt\n",
    "train.loc[(train[\"GarageYrBlt\"].apply(int) < 1950) & (train[\"GarageYrBlt\"].apply(int) >= 0), \"GarageBlt\"] = 'Before1950'\n",
    "train.loc[(train[\"GarageYrBlt\"].apply(int) < 1975) & (train[\"GarageYrBlt\"].apply(int) >= 1950), \"GarageBlt\"] = '1950to1974'\n",
    "train.loc[(train[\"GarageYrBlt\"].apply(int) < 2000) & (train[\"GarageYrBlt\"].apply(int) >= 1975), \"GarageBlt\"] = '1975to1999'\n",
    "train.loc[train[\"GarageYrBlt\"].apply(int) >= 2000, \"GarageBlt\"] = '2000OrLater'\n",
    "\n",
    "test.loc[(test[\"GarageYrBlt\"].apply(int) < 1950) & (test[\"GarageYrBlt\"].apply(int) >= 0), \"GarageBlt\"] = 'Before1950'\n",
    "test.loc[(test[\"GarageYrBlt\"].apply(int) < 1975) & (test[\"GarageYrBlt\"].apply(int) >= 1950), \"GarageBlt\"] = '1950to1974'\n",
    "test.loc[(test[\"GarageYrBlt\"].apply(int) < 2000) & (test[\"GarageYrBlt\"].apply(int) >= 1975), \"GarageBlt\"] = '1975to1999'\n",
    "test.loc[test[\"GarageYrBlt\"].apply(int) >= 2000, \"GarageBlt\"] = '2000OrLater'\n",
    "\n",
    "# YearRemodAdd -> YrRemodeled\n",
    "# Assume that there is no remodeling if built year == remodeled year.\n",
    "train.loc[train[\"YearRemodAdd\"] == train[\"YearBuilt\"], \"YrRemodeled\"] = 0\n",
    "train.loc[(train[\"YearRemodAdd\"] < 1950) & (train[\"YearRemodAdd\"] != 0), \"YrRemodeled\"] = 'Before1950'\n",
    "train.loc[(train[\"YearRemodAdd\"] < 1975) & (train[\"YearRemodAdd\"] >= 1950), \"YrRemodeled\"] = '1950to1974'\n",
    "train.loc[(train[\"YearRemodAdd\"] < 2000) & (train[\"YearRemodAdd\"] >= 1975), \"YrRemodeled\"] = '1975to1999'\n",
    "train.loc[train[\"YearRemodAdd\"] >= 2000, \"YrRemodeled\"] = '2000OrLater'\n",
    "\n",
    "test.loc[test[\"YearRemodAdd\"] == test[\"YearBuilt\"], \"YrRemodeled\"] = 0\n",
    "test.loc[(test[\"YearRemodAdd\"] < 1950) & (test[\"YearRemodAdd\"] != 0), \"YrRemodeled\"] = 'Before1950'\n",
    "test.loc[(test[\"YearRemodAdd\"] < 1975) & (test[\"YearRemodAdd\"] >= 1950), \"YrRemodeled\"] = '1950to1974'\n",
    "test.loc[(test[\"YearRemodAdd\"] < 2000) & (test[\"YearRemodAdd\"] >= 1975), \"YrRemodeled\"] = '1975to1999'\n",
    "test.loc[test[\"YearRemodAdd\"] >= 2000, \"YrRemodeled\"] = '2000OrLater'\n",
    "\n",
    "# YearBuilt -> YrBuilt\n",
    "train.loc[train[\"YearBuilt\"] < 1950, \"YrBuilt\"] = 'Before1950'\n",
    "train.loc[(train[\"YearBuilt\"] < 1975) & (train[\"YearBuilt\"] >= 1950), \"YrBuilt\"] = '1950to1974'\n",
    "train.loc[(train[\"YearBuilt\"] < 2000) & (train[\"YearBuilt\"] >= 1975), \"YrBuilt\"] = '1950to1974'\n",
    "train.loc[train[\"YearBuilt\"] >= 2000, \"YrBuilt\"] = '2000OrLater'\n",
    "\n",
    "test.loc[test[\"YearBuilt\"] < 1950, \"YrBuilt\"] = 'Before1950'\n",
    "test.loc[(test[\"YearBuilt\"] < 1975) & (test[\"YearBuilt\"] >= 1950), \"YrBuilt\"] = '1950to1974'\n",
    "test.loc[(test[\"YearBuilt\"] < 2000) & (test[\"YearBuilt\"] >= 1975), \"YrBuilt\"] = '1950to1974'\n",
    "test.loc[test[\"YearBuilt\"] >= 2000, \"YrBuilt\"] = '2000OrLater'\n",
    "\n",
    "train['GarageBlt'] = train['GarageBlt'].apply(lambda period: PERIOD_TO_VALUE[period])\n",
    "train['YrRemodeled'] = train['YrRemodeled'].apply(lambda period: PERIOD_TO_VALUE[period])\n",
    "train['YrBuilt'] = train['YrBuilt'].apply(lambda period: PERIOD_TO_VALUE[period])\n",
    "test['GarageBlt'] = test['GarageBlt'].apply(lambda period: PERIOD_TO_VALUE[period])\n",
    "test['YrRemodeled'] = test['YrRemodeled'].apply(lambda period: PERIOD_TO_VALUE[period])\n",
    "test['YrBuilt'] = test['YrBuilt'].apply(lambda period: PERIOD_TO_VALUE[period])\n",
    "\n",
    "def get_distinct_values(values):\n",
    "    return \",\".join([str(i) for i in (set(values))])\n",
    "\n",
    "# Check data binning results.\n",
    "print(\"GarageBlt column values:\", get_distinct_values(train[\"GarageBlt\"]))\n",
    "print(\"YrRemodeled column values:\", get_distinct_values(train[\"YrRemodeled\"]))\n",
    "print(\"YrBuilt column values:\", get_distinct_values(train[\"YrBuilt\"]))\n",
    "\n",
    "# Categorical value transformation.\n",
    "test = pd.get_dummies(test)\n",
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup For Binning Applied Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns after data binning. Continuous data is no longer meaningful.\n",
    "train.drop(['GarageYrBlt', 'YearRemodAdd', 'YearBuilt'], axis=1, inplace=True, errors='ignore')\n",
    "test.drop(['GarageYrBlt', 'YearRemodAdd', 'YearBuilt'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Value Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Categorical values need to be transformed to string data type since comparison by numeric value can mislead prediction.\n",
    "2) Convert MSSubClass, OverallCond, YrSold, and MoSold as String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MSSubClass'] = train['MSSubClass'].apply(str)\n",
    "train['OverallCond'] = train['OverallCond'].astype(str)\n",
    "train['YrSold'] = train['YrSold'].astype(str)\n",
    "train['MoSold'] = train['MoSold'].astype(str)\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Since SalePrice does not have zero value, log instead of log1p will be applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zero sales price number:1460, size of sales price:1460\n"
     ]
    }
   ],
   "source": [
    "##Tina - Commented this as log transformation was done initially\n",
    "#print(\"Non zero sales price number:{}, size of sales price:{}\"\n",
    "      #.format(np.count_nonzero(train['SalePrice']), len(train['SalePrice'])))\n",
    "#y = np.log(train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO(Mlaire): Remove following statements after the discussion.\n",
    "\n",
    "* How to transform numeric features done with default value or column drop\n",
    "* List all the features that needs Log transformation (including SalePrice output variable if needed)\n",
    "* Perform log-transformation and add into the dataframe as new columns\n",
    "* Normalize numeric features using SandardScaler?\n",
    "\n",
    "* How to transform categorical features?\n",
    "- Do we need one hot encoding?\n",
    "- using pandas getDummies? done\n",
    "- using sklearn ordinal encoding or one-hot encoding? How about simply changing numerical to string?\n",
    "- some other methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redefine Train and Dev Data Sets\n",
    "\n",
    "**After Data Mangling, we re-declare our train and dev data sets for fitting and prediction**<br>\n",
    "**We decided 20% from train_data will be assigned to dev data.**<br>\n",
    "**For numerical value, we prepare min-max scaling, leading data to fit it [0, 1]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, all the above analysis should result into these final data frames like the following.\n",
    "\n",
    "x: It is train data; it contains all relevant features and their values (transformed if relevant) without removed columns<br>\n",
    "y: Log transformed SalePrice column<br>\n",
    "test: Contains tranformed dataframe from train data set (same tranformation as that was done for train)<br>\n",
    "dev: Retrieves 20% from x<br>\n",
    "dev_labels: Retrieves 20% from y<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min max values of log transformed SalePrice (10.460242108190519, 13.534473028231162)\n",
      "There are 402 categorical variables; 402 discrete variables out of 419 total numeric vars.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>...</th>\n",
       "      <th>MoSold_5</th>\n",
       "      <th>MoSold_6</th>\n",
       "      <th>MoSold_7</th>\n",
       "      <th>MoSold_8</th>\n",
       "      <th>MoSold_9</th>\n",
       "      <th>YrSold_2006</th>\n",
       "      <th>YrSold_2007</th>\n",
       "      <th>YrSold_2008</th>\n",
       "      <th>YrSold_2009</th>\n",
       "      <th>YrSold_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows  402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OverallQual  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  \\\n",
       "0               7             1             0         2         1   \n",
       "1               6             0             1         2         0   \n",
       "2               7             1             0         2         1   \n",
       "3               7             1             0         1         0   \n",
       "4               8             1             0         2         1   \n",
       "5               5             1             0         1         1   \n",
       "6               8             1             0         2         0   \n",
       "7               7             1             0         2         1   \n",
       "8               7             0             0         2         0   \n",
       "9               5             1             0         1         0   \n",
       "10              5             1             0         1         0   \n",
       "11              9             1             0         3         0   \n",
       "12              5             1             0         1         0   \n",
       "13              7             0             0         2         0   \n",
       "14              6             1             0         1         1   \n",
       "15              7             0             0         1         0   \n",
       "16              6             1             0         1         0   \n",
       "17              4             0             0         2         0   \n",
       "18              5             1             0         1         1   \n",
       "19              5             0             0         1         0   \n",
       "20              8             0             0         3         1   \n",
       "21              7             0             0         1         0   \n",
       "22              8             0             0         2         0   \n",
       "23              5             1             0         1         0   \n",
       "24              5             1             0         1         0   \n",
       "25              8             0             0         2         0   \n",
       "26              5             0             1         1         0   \n",
       "27              8             1             0         2         0   \n",
       "28              5             1             0         1         0   \n",
       "29              4             0             0         1         0   \n",
       "...           ...           ...           ...       ...       ...   \n",
       "1138            6             1             0         2         0   \n",
       "1139            5             0             0         1         0   \n",
       "1140            5             1             0         1         0   \n",
       "1141            5             1             0         2         1   \n",
       "1142            8             1             0         3         0   \n",
       "1143            5             0             0         1         0   \n",
       "1144            4             1             0         1         0   \n",
       "1145            5             0             0         1         0   \n",
       "1146            6             1             0         2         0   \n",
       "1147            7             0             0         1         1   \n",
       "1148            7             0             0         1         0   \n",
       "1149            7             0             1         1         0   \n",
       "1150            6             0             0         1         0   \n",
       "1151            5             0             0         1         1   \n",
       "1152            6             0             0         1         0   \n",
       "1153            6             0             0         1         0   \n",
       "1154            7             0             0         1         2   \n",
       "1155            5             1             0         2         0   \n",
       "1156            5             0             1         2         0   \n",
       "1157            7             1             0         2         0   \n",
       "1158            8             0             0         2         0   \n",
       "1159            6             0             0         2         1   \n",
       "1160            6             0             0         2         1   \n",
       "1161            6             1             0         1         0   \n",
       "1162            5             0             0         1         0   \n",
       "1163            4             2             0         0         2   \n",
       "1164            5             1             0         1         1   \n",
       "1165            7             0             0         2         0   \n",
       "1166            8             0             0         2         0   \n",
       "1167            6             1             0         2         1   \n",
       "\n",
       "      BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageCars  \\\n",
       "0                3             1             8           0           2   \n",
       "1                3             1             6           1           2   \n",
       "2                3             1             6           1           2   \n",
       "3                3             1             7           1           3   \n",
       "4                4             1             9           1           3   \n",
       "5                1             1             5           0           2   \n",
       "6                3             1             7           1           2   \n",
       "7                3             1             7           2           2   \n",
       "8                2             2             8           2           2   \n",
       "9                2             2             5           2           1   \n",
       "10               3             1             5           0           1   \n",
       "11               4             1            11           2           3   \n",
       "12               2             1             4           0           1   \n",
       "13               3             1             7           1           3   \n",
       "14               2             1             5           1           1   \n",
       "15               2             1             5           0           2   \n",
       "16               2             1             5           1           2   \n",
       "17               2             2             6           0           2   \n",
       "18               3             1             6           0           2   \n",
       "19               3             1             6           0           1   \n",
       "20               4             1             9           1           3   \n",
       "21               3             1             6           1           1   \n",
       "22               3             1             7           1           2   \n",
       "23               3             1             6           1           2   \n",
       "24               3             1             6           1           1   \n",
       "25               3             1             7           1           3   \n",
       "26               3             1             5           0           2   \n",
       "27               3             1             7           1           3   \n",
       "28               2             1             6           2           1   \n",
       "29               1             1             4           0           1   \n",
       "...            ...           ...           ...         ...         ...   \n",
       "1138             2             1             5           2           2   \n",
       "1139             3             1             6           1           2   \n",
       "1140             2             1             4           0           2   \n",
       "1141             4             1             9           1           2   \n",
       "1142             4             1            11           1           3   \n",
       "1143             3             1             5           0           0   \n",
       "1144             2             1             5           0           1   \n",
       "1145             3             1             8           1           1   \n",
       "1146             3             1             5           1           2   \n",
       "1147             3             1             7           1           1   \n",
       "1148             2             1             5           1           1   \n",
       "1149             3             1             7           0           2   \n",
       "1150             2             1             4           1           1   \n",
       "1151             3             1             6           2           2   \n",
       "1152             2             1             6           1           2   \n",
       "1153             2             1             5           0           1   \n",
       "1154             4             1             8           2           2   \n",
       "1155             3             1             6           1           2   \n",
       "1156             3             1             6           1           2   \n",
       "1157             2             1             6           1           2   \n",
       "1158             3             1             7           0           3   \n",
       "1159             4             1             8           1           2   \n",
       "1160             3             1             7           1           2   \n",
       "1161             3             1             7           1           2   \n",
       "1162             3             1             5           1           2   \n",
       "1163             0             2             6           0           2   \n",
       "1164             2             1             5           1           2   \n",
       "1165             3             1             7           0           2   \n",
       "1166             3             1             7           0           3   \n",
       "1167             3             1             7           1           2   \n",
       "\n",
       "         ...       MoSold_5  MoSold_6  MoSold_7  MoSold_8  MoSold_9  \\\n",
       "0        ...              0         0         0         0         0   \n",
       "1        ...              1         0         0         0         0   \n",
       "2        ...              0         0         0         0         1   \n",
       "3        ...              0         0         0         0         0   \n",
       "4        ...              0         0         0         0         0   \n",
       "5        ...              0         0         0         0         0   \n",
       "6        ...              0         0         0         1         0   \n",
       "7        ...              0         0         0         0         0   \n",
       "8        ...              0         0         0         0         0   \n",
       "9        ...              0         0         0         0         0   \n",
       "10       ...              0         0         0         0         0   \n",
       "11       ...              0         0         1         0         0   \n",
       "12       ...              0         0         0         0         1   \n",
       "13       ...              0         0         0         1         0   \n",
       "14       ...              1         0         0         0         0   \n",
       "15       ...              0         0         1         0         0   \n",
       "16       ...              0         0         0         0         0   \n",
       "17       ...              0         0         0         0         0   \n",
       "18       ...              0         1         0         0         0   \n",
       "19       ...              1         0         0         0         0   \n",
       "20       ...              0         0         0         0         0   \n",
       "21       ...              0         1         0         0         0   \n",
       "22       ...              0         0         0         0         1   \n",
       "23       ...              0         1         0         0         0   \n",
       "24       ...              1         0         0         0         0   \n",
       "25       ...              0         0         1         0         0   \n",
       "26       ...              1         0         0         0         0   \n",
       "27       ...              1         0         0         0         0   \n",
       "28       ...              0         0         0         0         0   \n",
       "29       ...              1         0         0         0         0   \n",
       "...      ...            ...       ...       ...       ...       ...   \n",
       "1138     ...              1         0         0         0         0   \n",
       "1139     ...              1         0         0         0         0   \n",
       "1140     ...              0         1         0         0         0   \n",
       "1141     ...              0         0         0         0         0   \n",
       "1142     ...              0         0         0         0         0   \n",
       "1143     ...              0         0         1         0         0   \n",
       "1144     ...              0         0         1         0         0   \n",
       "1145     ...              0         0         0         1         0   \n",
       "1146     ...              1         0         0         0         0   \n",
       "1147     ...              0         0         1         0         0   \n",
       "1148     ...              0         0         0         1         0   \n",
       "1149     ...              0         0         1         0         0   \n",
       "1150     ...              0         0         0         0         0   \n",
       "1151     ...              0         0         0         0         0   \n",
       "1152     ...              0         0         1         0         0   \n",
       "1153     ...              0         1         0         0         0   \n",
       "1154     ...              1         0         0         0         0   \n",
       "1155     ...              0         0         1         0         0   \n",
       "1156     ...              0         0         0         0         0   \n",
       "1157     ...              0         0         1         0         0   \n",
       "1158     ...              0         1         0         0         0   \n",
       "1159     ...              0         0         1         0         0   \n",
       "1160     ...              0         0         1         0         0   \n",
       "1161     ...              0         0         0         0         0   \n",
       "1162     ...              1         0         0         0         0   \n",
       "1163     ...              0         0         0         0         0   \n",
       "1164     ...              0         1         0         0         0   \n",
       "1165     ...              0         0         0         0         1   \n",
       "1166     ...              0         0         0         0         0   \n",
       "1167     ...              0         0         0         0         0   \n",
       "\n",
       "      YrSold_2006  YrSold_2007  YrSold_2008  YrSold_2009  YrSold_2010  \n",
       "0               0            0            1            0            0  \n",
       "1               0            1            0            0            0  \n",
       "2               0            0            1            0            0  \n",
       "3               1            0            0            0            0  \n",
       "4               0            0            1            0            0  \n",
       "5               0            0            0            1            0  \n",
       "6               0            1            0            0            0  \n",
       "7               0            0            0            1            0  \n",
       "8               0            0            1            0            0  \n",
       "9               0            0            1            0            0  \n",
       "10              0            0            1            0            0  \n",
       "11              1            0            0            0            0  \n",
       "12              0            0            1            0            0  \n",
       "13              0            1            0            0            0  \n",
       "14              0            0            1            0            0  \n",
       "15              0            1            0            0            0  \n",
       "16              0            0            0            0            1  \n",
       "17              1            0            0            0            0  \n",
       "18              0            0            1            0            0  \n",
       "19              0            0            0            1            0  \n",
       "20              1            0            0            0            0  \n",
       "21              0            1            0            0            0  \n",
       "22              0            0            1            0            0  \n",
       "23              0            1            0            0            0  \n",
       "24              0            0            0            0            1  \n",
       "25              0            0            0            1            0  \n",
       "26              0            0            0            0            1  \n",
       "27              0            0            0            0            1  \n",
       "28              1            0            0            0            0  \n",
       "29              0            0            1            0            0  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "1138            0            0            0            1            0  \n",
       "1139            0            1            0            0            0  \n",
       "1140            0            0            1            0            0  \n",
       "1141            0            0            0            1            0  \n",
       "1142            0            1            0            0            0  \n",
       "1143            0            0            1            0            0  \n",
       "1144            0            0            0            0            1  \n",
       "1145            1            0            0            0            0  \n",
       "1146            1            0            0            0            0  \n",
       "1147            0            0            0            1            0  \n",
       "1148            0            0            1            0            0  \n",
       "1149            0            0            0            1            0  \n",
       "1150            0            1            0            0            0  \n",
       "1151            1            0            0            0            0  \n",
       "1152            1            0            0            0            0  \n",
       "1153            0            0            1            0            0  \n",
       "1154            0            0            1            0            0  \n",
       "1155            0            1            0            0            0  \n",
       "1156            0            0            1            0            0  \n",
       "1157            0            0            0            1            0  \n",
       "1158            0            0            1            0            0  \n",
       "1159            0            0            1            0            0  \n",
       "1160            0            0            0            0            1  \n",
       "1161            0            0            1            0            0  \n",
       "1162            0            1            0            0            0  \n",
       "1163            0            0            1            0            0  \n",
       "1164            0            1            0            0            0  \n",
       "1165            0            0            0            1            0  \n",
       "1166            0            0            0            0            1  \n",
       "1167            1            0            0            0            0  \n",
       "\n",
       "[1168 rows x 402 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define cutoff to bisect train and test data.\n",
    "cutoff = (len(train) * 80) // 100\n",
    "\n",
    "dev = train[cutoff:]\n",
    "dev_labels = y[cutoff:]\n",
    "x = train[:cutoff]\n",
    "y = y[:cutoff]\n",
    "\n",
    "def get_min_max_value(values):\n",
    "    return (min(values), max(values))\n",
    "print(\"min max values of log transformed SalePrice\", get_min_max_value(y))\n",
    "assert len(x.index) == cutoff # Confirm length is correct\n",
    "\n",
    "# Remove SalePrice since it is y in the model.\n",
    "x.drop(['SalePrice'], axis=1, inplace=True, errors='ignore')\n",
    "dev.drop(['SalePrice'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Min-max scaling.\n",
    "# (val - min) / (max - min), that all values will fit it in the range of [0, 1]\n",
    "numerical_features = x.select_dtypes(exclude=['object']).columns\n",
    "categorical_features = x.select_dtypes(include=[\"object\"]).columns\n",
    "discrete_features = []\n",
    "for var in numerical_features:\n",
    "    if len(train[var].unique()) < 20:\n",
    "        discrete_features.append(var)\n",
    "print('There are {} categorical variables; {} discrete variables out of {} total numeric vars.'\n",
    "      .format(len(discrete_features), len(discrete_features), len(numerical_features)))\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_numerical_feature_scaled = min_max_scaler.fit_transform(x[numerical_features])\n",
    "x[categorical_features]\n",
    "x[discrete_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we plan to perform:\n",
    "* Dimentionality reduction\n",
    "* Building and tuning home prices prediction models\n",
    "\n",
    "From 79 available features (input variables), we will use statistically and practically significant variables for modeling after data mangling. We also will try to watch out for collinearity and spurious relationships.  \n",
    "\n",
    "We plan to start with LinearRegression model because of the predictive nature of the problem. We will also try other supervised learning models such as Random Forest and Gradient Boosting Tree if they increase accuracy.\n",
    "\n",
    "We will be working on two broad sets of algorithms:\n",
    "1. Linear Models\n",
    "2. Non Linear relationships using Random Forests\n",
    "\n",
    "#### Linear Models\n",
    "For linear models, we will try and test with the regular OLS model, and the regularized linear models of Ridge Regression, Least Absolute Shrinkage and Selection Operator (LASSO), and Elastic Net. \n",
    "\n",
    "For model tuning, Sklearn's grid search with CV function will be used to find the optimal hyper-parameter values.\n",
    "\n",
    "To assess the predictive performance of regression models, we can compute the mean sum of squared errors and the related summary metric. Furthermore, we can also use graphical approach of residual plots to diagnose problems of linear regression models\n",
    "\n",
    "We can apply regularization to our regression models to reduce the model complexity and avoid overfitting.\n",
    "\n",
    "#### Non Linear relationships using Random Forests\n",
    "For the decision tree algorithm, we will subdivide the input space into smaller regions so that it's more manageable. As Decision tree algorithm does not require any transformation of the features for nonlinear data, there will not be any feature transformation in this section. Since random forests are less sensitive to outliers in the dataset we are assuming at this point that it will not require much parameter tuning. The only parameter that will require experimenting might be number of trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(mean_squared_error(predictions,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d35959b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy 0.09323462797314742 \tRMSE 0.1946384621654741 \tRegression score 0.7523293104875655\n"
     ]
    }
   ],
   "source": [
    "## Fit lr using the train data and labels taken above, predict dev data.\n",
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "prediction = lr.predict(dev_data)\n",
    "\n",
    "## Distance of actuals vs predictors\n",
    "accuracy = abs(prediction - dev_labels)\n",
    "\n",
    "## Plots prediction vs actual sale price\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.scatter(prediction, dev_labels)\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.xlabel(\"Predicted Sale Price\")\n",
    "plt.ylabel(\"Actual Sale Price\")\n",
    "plt.show()\n",
    "\n",
    "## Print out the mean accuracy, rmse, and lr score.\n",
    "print(\"Mean accuracy %s \\tRMSE %s \\tRegression score %s\" \\\n",
    "    %(accuracy.mean(), rmse(prediction, dev_labels), lr.score(dev_data, dev_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest rmsle by Lasso model is 0.1299\n",
      "This occurs when alpha is 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d35980ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS = 10\n",
    "\n",
    "def rmsle_cv(model, x, test_labels):\n",
    "    # KFold is for cross-validation\n",
    "    kf = KFold(N_FOLDS, shuffle=True, random_state=0).get_n_splits(x)\n",
    "    rsle = np.sqrt(-cross_val_score(model, x, test_labels, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return rsle.mean()\n",
    "\n",
    "def lasso_fn(alphas):\n",
    "    rmsle_list = []\n",
    "    for i in alphas:\n",
    "        lasso_reg = Lasso(alpha=i, normalize=True)\n",
    "        rmsle_list.append(rmsle_cv(lasso_reg, x, y))\n",
    "\n",
    "    plt.plot(alphas, rmsle_list)\n",
    "    plt.xlabel(\"alpha\")\n",
    "    plt.ylabel(\"rmsle\")\n",
    "    plt.tick_params(\"L1 Lasso Model\")\n",
    "\n",
    "    print(\"The smallest rmsle by Lasso model is {:.4f}\".format(min(rmsle_list)))\n",
    "    print(\"This occurs when alpha is {}\".format(alphas[np.argmin(rmsle_list)]))\n",
    "\n",
    "    return alphas[np.argmin(rmsle_list)]\n",
    "\n",
    "ALPHAS = [0.00001, 0.0001, 0.001, 0.005, 0.01, 0.05]\n",
    "min_alpha_Lasso = lasso_fn(ALPHAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Result Analysis\n",
    "\n",
    "The first model we ran is Linear regression with L1 Regularization which is known as Lasso Model. This model outputs a sparse matrix and has built-in feature selection due to the number of coefficients that return a value of zero.[1] We picked some alpha, then evaluate the different Lasso models using k fold cross-validation. We found the optimal alpha as 0.0001 for Lasso that has an average RMSLE of 0.1299. Please note that the higher alpha is, the more coefficients become zero.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'EN': ElasticNet(),\n",
    "    'RF': RandomForestRegressor(n_estimators=1000),\n",
    "    'GBR': GradientBoostingRegressor(n_estimators=1000, loss='huber')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'LinearRegression': { },\n",
    "    'Ridge': { 'alpha': [.001, 0.1, 1.0] },\n",
    "    'Lasso': { 'alpha': [.001, 0.1, 1.0] },\n",
    "    'EN': { 'alpha': [0.1, 1.0] },\n",
    "    'RF': {'max_depth': [4,6],\n",
    "            'min_samples_leaf': [3, 5, 9],\n",
    "            'max_features': [1.0, 0.3, 0.1]},\n",
    "    'GBR': {'learning_rate': [0.1, 0.05, 0.02],\n",
    "              'max_depth': [4, 6],\n",
    "              'min_samples_leaf': [3, 5, 9],\n",
    "              'max_features': [1.0, 0.3, 0.1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gridcv(models,params,X,y,cv=3,n_jobs=1,verbose=1,scoring=None,refit=False):\n",
    "    \n",
    "    keys = models.keys()\n",
    "    grid_searches = {}\n",
    "    for key in keys:\n",
    "        print(\"Running GridSearchCV for %s.\" % key)\n",
    "        model = models[key]\n",
    "        param_grid = params[key]\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring, refit=refit)\n",
    "        grid_search.fit(X,y)\n",
    "        #print(gs.cv_results_)\n",
    "        df0 = pd.DataFrame(grid_search.cv_results_)\n",
    "        df =pd.DataFrame(grid_search.cv_results_)[['params','mean_train_score','mean_test_score']]\n",
    "        df\n",
    "        print(df)\n",
    "        grid_searches[key] = grid_search\n",
    "       \n",
    "    #print(grid_searches)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LinearRegression.\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  params  mean_train_score  mean_test_score\n",
      "0     {}          0.958555    -5.875305e+08\n",
      "Running GridSearchCV for Ridge.\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    2.2s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             params  mean_train_score  mean_test_score\n",
      "0  {'alpha': 0.001}          0.958555         0.834304\n",
      "1    {'alpha': 0.1}          0.958188         0.856292\n",
      "2    {'alpha': 1.0}          0.953788         0.888989\n",
      "Running GridSearchCV for Lasso.\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    2.7s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             params  mean_train_score  mean_test_score\n",
      "0  {'alpha': 0.001}          0.931342         0.895579\n",
      "1    {'alpha': 0.1}          0.764388         0.736182\n",
      "2    {'alpha': 1.0}          0.746230         0.728258\n",
      "Running GridSearchCV for EN.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           params  mean_train_score  mean_test_score\n",
      "0  {'alpha': 0.1}          0.820190         0.799854\n",
      "1  {'alpha': 1.0}          0.751017         0.728769\n",
      "Running GridSearchCV for RF.\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   51.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_train_score  \\\n",
      "0   {'max_depth': 4, 'max_features': 1.0, 'min_sam...          0.868711   \n",
      "1   {'max_depth': 4, 'max_features': 1.0, 'min_sam...          0.866474   \n",
      "2   {'max_depth': 4, 'max_features': 1.0, 'min_sam...          0.861202   \n",
      "3   {'max_depth': 4, 'max_features': 0.3, 'min_sam...          0.864810   \n",
      "4   {'max_depth': 4, 'max_features': 0.3, 'min_sam...          0.861961   \n",
      "5   {'max_depth': 4, 'max_features': 0.3, 'min_sam...          0.855625   \n",
      "6   {'max_depth': 4, 'max_features': 0.1, 'min_sam...          0.832724   \n",
      "7   {'max_depth': 4, 'max_features': 0.1, 'min_sam...          0.828954   \n",
      "8   {'max_depth': 4, 'max_features': 0.1, 'min_sam...          0.821324   \n",
      "9   {'max_depth': 6, 'max_features': 1.0, 'min_sam...          0.930732   \n",
      "10  {'max_depth': 6, 'max_features': 1.0, 'min_sam...          0.919895   \n",
      "11  {'max_depth': 6, 'max_features': 1.0, 'min_sam...          0.900625   \n",
      "12  {'max_depth': 6, 'max_features': 0.3, 'min_sam...          0.921963   \n",
      "13  {'max_depth': 6, 'max_features': 0.3, 'min_sam...          0.910177   \n",
      "14  {'max_depth': 6, 'max_features': 0.3, 'min_sam...          0.891740   \n",
      "15  {'max_depth': 6, 'max_features': 0.1, 'min_sam...          0.896996   \n",
      "16  {'max_depth': 6, 'max_features': 0.1, 'min_sam...          0.884285   \n",
      "17  {'max_depth': 6, 'max_features': 0.1, 'min_sam...          0.863907   \n",
      "\n",
      "    mean_test_score  \n",
      "0          0.806508  \n",
      "1          0.807893  \n",
      "2          0.808890  \n",
      "3          0.814917  \n",
      "4          0.815169  \n",
      "5          0.812891  \n",
      "6          0.789760  \n",
      "7          0.788176  \n",
      "8          0.785725  \n",
      "9          0.844123  \n",
      "10         0.843249  \n",
      "11         0.838880  \n",
      "12         0.850746  \n",
      "13         0.848333  \n",
      "14         0.842215  \n",
      "15         0.833539  \n",
      "16         0.830504  \n",
      "17         0.821810  \n",
      "Running GridSearchCV for GBR.\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_train_score  \\\n",
      "0   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.995313   \n",
      "1   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.992764   \n",
      "2   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.986993   \n",
      "3   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.994556   \n",
      "4   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.992022   \n",
      "5   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.985802   \n",
      "6   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.993871   \n",
      "7   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.991471   \n",
      "8   {'learning_rate': 0.1, 'max_depth': 4, 'max_fe...          0.984488   \n",
      "9   {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.996812   \n",
      "10  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.994203   \n",
      "11  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.988343   \n",
      "12  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.996442   \n",
      "13  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.993112   \n",
      "14  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.988899   \n",
      "15  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.995910   \n",
      "16  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.992753   \n",
      "17  {'learning_rate': 0.1, 'max_depth': 6, 'max_fe...          0.987848   \n",
      "18  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.993059   \n",
      "19  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.989514   \n",
      "20  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.983113   \n",
      "21  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.992006   \n",
      "22  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.988196   \n",
      "23  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.982404   \n",
      "24  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.990226   \n",
      "25  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.986036   \n",
      "26  {'learning_rate': 0.05, 'max_depth': 4, 'max_f...          0.977406   \n",
      "27  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.996622   \n",
      "28  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.992623   \n",
      "29  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.986955   \n",
      "30  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.996339   \n",
      "31  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.992815   \n",
      "32  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.986379   \n",
      "33  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.995038   \n",
      "34  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.991609   \n",
      "35  {'learning_rate': 0.05, 'max_depth': 6, 'max_f...          0.984891   \n",
      "36  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.985713   \n",
      "37  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.980783   \n",
      "38  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.973130   \n",
      "39  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.983572   \n",
      "40  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.978310   \n",
      "41  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.970097   \n",
      "42  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.979791   \n",
      "43  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.973863   \n",
      "44  {'learning_rate': 0.02, 'max_depth': 4, 'max_f...          0.963975   \n",
      "45  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.994179   \n",
      "46  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.989888   \n",
      "47  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.983076   \n",
      "48  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.993881   \n",
      "49  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.988904   \n",
      "50  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.980824   \n",
      "51  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.991526   \n",
      "52  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.985710   \n",
      "53  {'learning_rate': 0.02, 'max_depth': 6, 'max_f...          0.976350   \n",
      "\n",
      "    mean_test_score  \n",
      "0          0.891426  \n",
      "1          0.888928  \n",
      "2          0.887117  \n",
      "3          0.898143  \n",
      "4          0.896559  \n",
      "5          0.893776  \n",
      "6          0.898834  \n",
      "7          0.898400  \n",
      "8          0.897860  \n",
      "9          0.876284  \n",
      "10         0.873700  \n",
      "11         0.875145  \n",
      "12         0.889090  \n",
      "13         0.888724  \n",
      "14         0.884854  \n",
      "15         0.894691  \n",
      "16         0.890804  \n",
      "17         0.890354  \n",
      "18         0.893072  \n",
      "19         0.890867  \n",
      "20         0.889884  \n",
      "21         0.899646  \n",
      "22         0.899223  \n",
      "23         0.895623  \n",
      "24         0.903136  \n",
      "25         0.903955  \n",
      "26         0.903197  \n",
      "27         0.881334  \n",
      "28         0.877249  \n",
      "29         0.879140  \n",
      "30         0.890230  \n",
      "31         0.889751  \n",
      "32         0.890715  \n",
      "33         0.893142  \n",
      "34         0.897242  \n",
      "35         0.895428  \n",
      "36         0.894256  \n",
      "37         0.892265  \n",
      "38         0.889062  \n",
      "39         0.903908  \n",
      "40         0.901420  \n",
      "41         0.896686  \n",
      "42         0.905334  \n",
      "43         0.905810  \n",
      "44         0.900935  \n",
      "45         0.878063  \n",
      "46         0.876506  \n",
      "47         0.880324  \n",
      "48         0.894113  \n",
      "49         0.893998  \n",
      "50         0.892508  \n",
      "51         0.896303  \n",
      "52         0.897775  \n",
      "53         0.897270  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "fit_gridcv(models,params,x,y,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial dependence\n",
    "\n",
    "  * Relationship between the response and a set of features, marginalizing over all other features\n",
    "  * Intuitively: expected response as a function of the features we conditioned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (11,7)\n",
    "type(est.feature_importances_)\n",
    "fx_imp = pd.Series(est.feature_importances_, index=features)\n",
    "fx_imp /= fx_imp.max()  # normalize\n",
    "#fx_imp.sort()\n",
    "fx_imp.nlargest(20).plot(kind='barh', figsize=FIGSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial dependence\n",
    "\n",
    "  * Relationship between the response and a set of features, marginalizing over all other features\n",
    "  * Intuitively: expected response as a function of the features we conditioned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "features = ['MasVnrArea', 'MoSold', 'MiscVal', 'FullBath', 'SaleCondition_Family','OpenPorchSF', '2ndFlrSF', 'EnclosedPorch',\n",
    "           'WoodDeckSF','TotalBsmtSF_Log']\n",
    "fig, axs = plot_partial_dependence(est, X_train_data, features, feature_names=features, \n",
    "                                   n_cols=6, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Key Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will present our key findings in terms of key predictor variables and their parameter values. We will also summary the modeling process and learning from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: <a href=\"https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\">L1 and L2 Regulazation Model</a><br>\n",
    "[2]: <a href=\"https://chrisalbon.com/machine_learning/linear_regression/effect_of_alpha_on_lasso_regression/\">Effect of Alpha on Lasso Regression</a><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
