{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project: House Prices Prediction\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques  \n",
    "\n",
    "### Team MLAIRE: Chi Iong Ansjory, Prabhat Tripathi, Soodong Kim, Tina Agarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to predict sale price of residential homes in Ames, Iowa based on the given training and test data sets. There are 79 explanatory variables describing different aspects of residential homes with 1460 observations in both training and test data sets (this is different than previous class projects where train data is usually larger than test data set). \n",
    "\n",
    "The output variable (SalePrice) is quantitative (continuous) whereas the explanatory (LHS) variables are a combination of quantitative (continuous) and categorical variables. \n",
    "\n",
    "Considering the size and nature of the data set, and informed by our domain understanding, we beleive that *feature engineering* -- crafting data features optimized for machine learning -- is key for better modeling for this problem. Specifically, we plan to perform following:\n",
    "\n",
    "- Univariate analysis of output and explanatory variables: weed out spurious or wrong values. Understand patterns and outliers for each variable. Allow for missing values (NaN) imputations.\n",
    "- Transform categorical variables into numeric (using dummy variables?)\n",
    "- Check if log transformation of output and explanatory variables helps better model performance\n",
    "- Identify and remove unhelpful explanatory variables (using correlation matrix or using techniques such as LASSO)\n",
    "- Identify and remove multicollinearity, if present\n",
    "- Advance feature engineering techniques such as PCA?\n",
    "\n",
    "We also have to watch out for overfitting considering there are a large number of input variables (compared to the training data size).\n",
    "\n",
    "We plan to begin with (multiple) LinearRegression model (for speed) and if the accuracy is not satisfactory, we would try other models such as random forest and gradient-boosting tree. If needed, we may have to ensemble all these models for better overall accuracy. We will split test data into two random sets and use one as \"dev\" data during model buidling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Each plot will not open a new window. \n",
    "# required libraries\n",
    "## pandas\n",
    "## seaborn\n",
    "## XGBoost -- allows for correlated features\n",
    "%matplotlib inline\n",
    "\n",
    "# Import relevant libraries.\n",
    "\n",
    "# General libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "# Libraries for files\n",
    "import os\n",
    "\n",
    "# Python fundamental libraries\n",
    "import collections\n",
    "\n",
    "# Disable warnings for more clear output\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shapes of train and test datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Please keep this relative path access to data.\n",
    "dir_name = os.getcwd()\n",
    "train_filename = os.path.join(dir_name, 'data/train.csv')\n",
    "test_filename = os.path.join(dir_name, 'data/test.csv')\n",
    "\n",
    "# Reading the data\n",
    "train = pd.read_csv(train_filename)\n",
    "test  = pd.read_csv(test_filename)\n",
    "train_ = train.copy()\n",
    "test_ = test.copy()\n",
    "\n",
    "print(\"original shapes of train and test datasets\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we summarize the train dataset features:  \n",
    "* categorize 80 features into numerical, categorical. Among numerical features, distinguish \"discrete\" values features\n",
    "* print a summary of numerical features with info such as: mean, min, max, number of NaNs, isDiscrete\n",
    "* print a summary of categorical features with info such as: number of NaNs, number of disntict values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions of variables are based on https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data. Variable types are either categorical, or discrete/non-discrete numeric. There are 4 different segments: Sale (sales transaction of house), Location (where the house located), Building (physical characteristics), Space (space properties of house). There are 3 levels of expectations: High, Medium, and Low of how the variables are related to the sale price.\n",
    "\n",
    "| Variable | Description | Type | Segment | Expectation | Comments |\n",
    "| --- | --- | --- | --- |\n",
    "| SalePrice | Property's sale price in dollars | Numeric | Building | Target Variable | |\n",
    "| MSSubClass | Building class | Categorical | Building | Low | |\n",
    "| MSZoning | General zoning classification | Categorical | Building | Low | |\n",
    "| LotFrontage | Linear feet of street connected to property | Numeric | Space | Medium | Needs missing data handling |\n",
    "| LotArea | Lot size in square feet | Numeric | Space | High | |\n",
    "| Street | Type of road access | Categorical | Location | Low | |\n",
    "| Alley | Type of alley access | Categorical | Location | Low | Needs NA to be renamed |\n",
    "| LotShape | General shape of property | Categorical | Location | Low | |\n",
    "| LandContour | Flatness of the property | Categorical | Location | Low | |\n",
    "| Utilities | Type of utilities available | Categorical | Location | Low | Can be removed since all are AllPub |\n",
    "| LotConfig | Lot configuration | Categorical | Location | Medium | |\n",
    "| LandSlope | Slope of property | Categorical | Location | Low | |\n",
    "| Neighborhood | Physical locations within Ames city limits | Categorical | Location | High | |\n",
    "| Condition1 | Proximity to main road or railroad | Categorical | Location | Medium | |\n",
    "| Condition2 | Proximity to main road or railroad (if a second is present) | Categorical | Location | Low | |\n",
    "| BldgType | Type of dwelling | Categorical | Building | Low | |\n",
    "| HouseStyle | Style of dwelling | Categorical | Building | Low | |\n",
    "| OverallQual | Overall material and finish quality | Categorical | Building | High | |\n",
    "| OverallCond | Overall condition rating | Categorical | Building | Medium | |\n",
    "| YearBuilt | Original construction date | Categorical | Building | High | |\n",
    "| YearRemodAdd | Remodel date | Categorical | Building | Medium | |\n",
    "| RoofStyle | Type of roof | Categorical | Building | Medium | |\n",
    "| RoofMatl | Roof material | Categorical | Building | Low | |\n",
    "| Exterior1st | Exterior covering on house | Categorical | Building | Medium | |\n",
    "| Exterior2nd | Exterior covering on house (if more than one material) | Categorical | Building | Low | |\n",
    "| MasVnrType | Masonry veneer type | Categorical | Building | Low | |\n",
    "| MasVnrArea | Masonry veneer area in square feet | Numeric | Space | Low | |\n",
    "| ExterQual | Exterior material quality | Categorical | Building | Low | |\n",
    "| ExterCond | Present condition of the material on the exterior | Categorical | Building | Medium | |\n",
    "| Foundation | Type of foundation | Categorical | Building | Low | |\n",
    "| BsmtQual | Height of the basement | Categorical | Building | Low | |\n",
    "| BsmtCond | General condition of the basement | Categorical | Building | Medium | |\n",
    "| BsmtExposure | Walkout or garden level basement walls | Categorical | Building | Low | |\n",
    "| BsmtFinType1 | Quality of basement finished area | Categorical | Building | Low | |\n",
    "| BsmtFinSF1 | Type 1 finished square feet | Numeric | Space | Medium | |\n",
    "| BsmtFinType2 | Quality of second finished area (if present) | Categorical | Building | Low | |\n",
    "| BsmtFinSF2 | Type 2 finished square feet | Numeric | Space | Low | |\n",
    "| BsmtUnfSF | Unfinished square feet of basement area | Numeric | Space | Medium | |\n",
    "| TotalBsmtSF | Total square feet of basement area | Numeric | Space | High | |\n",
    "| Heating | Type of heating | Categorical | Building | Low | |\n",
    "| HeatingQC | Heating quality and condition | Categorical | Building | Low | |\n",
    "| CentralAir | Central air conditioning | Categorical | Building | Medium | |\n",
    "| Electrical | Electrical system | Categorical | Building | Low | |\n",
    "| 1stFlrSF | First Floor square feet | Numeric | Space | Medium | |\n",
    "| 2ndFlrSF | Second floor square feet | Numeric | Space | Medium | |\n",
    "| LowQualFinSF | Low quality finished square feet (all floors) | Numeric | Space | Low | |\n",
    "| GrLivArea | Above grade (ground) living area square feet | Numeric | Space | High | |\n",
    "| BsmtFullBath | Basement full bathrooms | Numeric | Building | Low | Discrete |\n",
    "| BsmtHalfBath | Basement half bathrooms | Numeric | Building | Low | Discrete |\n",
    "| FullBath | Full bathrooms above grade | Numeric | Building | Medium | Discrete |\n",
    "| HalfBath | Half baths above grade | Numeric | Building | Low | Discrete |\n",
    "| BedroomAbvGr | Number of bedrooms above basement level | Numeric | Building | High | Discrete |\n",
    "| Kitchen | Number of kitchens | Numeric | Building | Low | Discrete|\n",
    "| KitchenQual | Kitchen quality | Categorical | Building | Medium | |\n",
    "| TotRmsAbvGrd | Total rooms above grade (does not include bathrooms) | Numeric | Building | Medium | Discrete |\n",
    "| Functional | Home functionality rating | Categorical | Building | Low | |\n",
    "| Fireplaces | Number of fireplaces | Numeric | Building | Medium | Discrete |\n",
    "| FireplaceQu | Fireplace quality | Categorical | Building | Low | |\n",
    "| GarageType | Garage location | Categorical | Building | Low | |\n",
    "| GarageYrBlt | Year garage was built | Categorical | Building | Low | |\n",
    "| GarageFinish | Interior finish of the garage | Categorical | Building | Low | |\n",
    "| GarageCars | Size of garage in car capacity | Numeric | Building | High | Discrete |\n",
    "| GarageArea | Size of garage in square feet | Numeric | Space | Medium | |\n",
    "| GarageQual | Garage quality | Categorical | Building | Low | |\n",
    "| GarageCond | Garage condition | Categorical | Building | Low | |\n",
    "| PavedDrive | Paved driveway | Categorical | Building | Medium | |\n",
    "| WoodDeckSF | Wood deck area in square feet | Numeric | Space | Low | |\n",
    "| OpenPorchSF | Open porch area in square feet | Numeric | Space | Low | |\n",
    "| EnclosedPorch | Enclosed porch area in square feet | Numeric | Space | Low | |\n",
    "| 3SsnPorch | Three season porch area in square feet | Numeric | Space | Low | |\n",
    "| ScreenPorch | Screen porch area in square feet | Numeric | Space | Low | |\n",
    "| PoolArea | Pool area in square feet | Numeric | Space | Medium | |\n",
    "| PoolQC | Pool quality | Categorical | Building | Low | |\n",
    "| Fence | Fence quality | Categorical | Building | Low | |\n",
    "| MiscFeature | Miscellaneous feature not covered in other categories | Categorical | Building | Low | |\n",
    "| MiscVal | $Value of miscellaneous feature | Numeric | Building | Low | |\n",
    "| MoSold | Month Sold | Categorical | Sale | Medium | |\n",
    "| YrSold | Year Sold | Categorical | Sale | High | |\n",
    "| SaleType | Type of sale | Categorical | Sale | Medium | |\n",
    "| SaleCondition | Condition of sale | Categorical | Sale | High | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-variate analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify 15-20 interesting features and perform their data analysis\n",
    "* SalePrice\n",
    "* numeric1 feature\n",
    "* numeric2 feature\n",
    "* discrete1 feature\n",
    "*...\n",
    "* categorical1 feature\n",
    "...\n",
    "\n",
    "We can use plots such as Histogram, boxplot to understand their distribution and general structure of these features\n",
    "* note outliers\n",
    "* note if some transformation of a feature would help\n",
    "* practical and statistical significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis for explanatory variable *SalePrice*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Kurtosis\n",
    "print(\"Skewness: \", train['SalePrice'].skew())\n",
    "print(\"Kurtosis: \", train['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSSubClass* 20 (1-STORY 1946 & NEWER ALL STYLES) and 60 (2-STORY 1946 & NEWER) have major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['MSSubClass'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSZoning* RL (Residential Low Density) has the major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['MSZoning'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LotFrontage* needs to have missing data removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis for numeric feature *LotArea*, which is continuous and related to segment Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "train['LotArea'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Kurtosis\n",
    "print(\"Skewness: \", train['LotArea'].skew())\n",
    "print(\"Kurtosis: \", train['LotArea'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Street* Pave has major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['Street'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alley* needs to have NA (No Alley Access) renamed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LotShape Reg (Regular) has major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['LotShape'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LandContour* Lvl (Near Flat/Level) has major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['LandContour'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LotConfig* Inside (Inside Lot) has major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['LotConfig'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LandSlope* Gtl (Gentle Slope) has major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['LandSlope'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['Neighborhood'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['Condition1'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BldgType* 1Fam (Single Family Detached) has major contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['BldgType'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['HouseStyle'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['OverallQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['OverallCond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['YearBuilt'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['YearRemodAdd'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis for numeric feature *BedroomAbvGr*, which is discrete and related to segment Building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "train['BedroomAbvGr'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train['BedroomAbvGr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis for categorical feature *MoSold*, which is related to segment Sale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['MoSold'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis for categorical feature *SaleCondition*, which is related to segment Sale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "train['SaleCondition'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For relationship with numeric features, picking 2 numeric features (TotalBsmtSF, GrLivArea) with expectation \"high\" from \"building\" segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "var = 'TotalBsmtSF'\n",
    "train[var].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of totalbsmtsf/saleprice\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "var = 'GrLivArea'\n",
    "train[var].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "sns.distplot(train[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of grlivarea/saleprice\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For relationship with categorical features, picking categorical features (OverallQual, YearBuilt) with expectation \"high\" from \"building\" segment, and categorical feature (Neighborhood) with expectation \"high\" from \"location\" segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot overallqual/saleprice\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot yearbuilt/saleprice\n",
    "var = 'YearBuilt'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot neighborhood/saleprice\n",
    "var = 'Neighborhood'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For relationship with discrete features, picking numeric discrete features (GarageCars) with expectation \"high\" from \"building\" segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot garagecars/saleprice\n",
    "var = 'GarageCars'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot garagecars/saleprice\n",
    "var = 'MSSubClass'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-variate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find correlation between SalePrice and a set of important idenfied features (10-15) and plot their correlation matrix. Since Id is irrelevant column, it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix showing evidence of multicollearity\n",
    "# Remove Id column which is totally un\n",
    "copied_train = train.copy()\n",
    "copied_train = copied_train.drop(['Id'],axis=1,errors='raise')\n",
    "mask = np.zeros_like(corrmat)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corrmat = copied_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, mask=mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saleprice correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(train[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot after log transformation showing allevation of homoscedasticity problem\n",
    "plt.scatter(np.log(train['GrLivArea']), np.log(train['SalePrice']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we decided to check how many missing values are existing for each column. Since mssing values can mislead prediction, analysis is necessary. Please note that data mangling or data transformation will be covered by the other section (Feature Engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Number of Missing Data</th>\n",
       "      <th>Missing Data Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total Number of Missing Data  Missing Data Percentage\n",
       "PoolQC                                1453                99.520548\n",
       "MiscFeature                           1406                96.301370\n",
       "Alley                                 1369                93.767123\n",
       "Fence                                 1179                80.753425\n",
       "FireplaceQu                            690                47.260274\n",
       "LotFrontage                            259                17.739726\n",
       "GarageCond                              81                 5.547945\n",
       "GarageType                              81                 5.547945\n",
       "GarageYrBlt                             81                 5.547945\n",
       "GarageFinish                            81                 5.547945\n",
       "GarageQual                              81                 5.547945\n",
       "BsmtExposure                            38                 2.602740\n",
       "BsmtFinType2                            38                 2.602740\n",
       "BsmtFinType1                            37                 2.534247\n",
       "BsmtCond                                37                 2.534247\n",
       "BsmtQual                                37                 2.534247\n",
       "MasVnrArea                               8                 0.547945\n",
       "MasVnrType                               8                 0.547945\n",
       "Electrical                               1                 0.068493\n",
       "Utilities                                0                 0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate about missing data.\n",
    "# Analyze top 20 columns having missing data.\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum() / train.isnull().count() * 100).sort_values(ascending=False)\n",
    "missing_data = pd.concat(\n",
    "    [total, percent], axis=1, keys=[\"Total Number of Missing Data\", \"Missing Data Percentage\"])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Drop columns with 80% missing data since filling default data for 80% makes this column to be skewed. <br>\n",
    "2) Also drop the 'Id' column which is irrelevant to model. <br>\n",
    "3) In addition to 'Id', 'LotFrontage' column will not be used since defining default value for linear feat is not feasible.<br>\n",
    "4) Columns not dropped will be re-visited in the follow-up section 'Feature Engineering'. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_will_be_removed = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id', 'LotFrontage']\n",
    "\n",
    "train.drop(columns_will_be_removed, axis=1, inplace=True, errors='ignore')\n",
    "test.drop(columns_will_be_removed, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Double check whether above columns are removed\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum() / train.isnull().count() * 100).sort_values(ascending=False)\n",
    "assert percent[0] < 50.0\n",
    "\n",
    "def assert_column_drop(data, col_names):\n",
    "    for col_name in col_names:\n",
    "        assert col_name not in data, \"%s should not exist\" % col_name\n",
    "\n",
    "assert_column_drop(train, ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id', 'LotFrontage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train after removing columns with 80% missing data: (1460, 75)\n",
      "Shape of test after removing columns with 80% missing data: (1459, 74)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train after removing columns with 80% missing data: {}\".format(train.shape))\n",
    "print(\"Shape of test after removing columns with 80% missing data: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing Values\n",
    "\n",
    "1) For string data columns, default value can be guessed from the documnation. <br>\n",
    "2) For non string data columns, zero can be assigned. Although zero can mislead prediction, there will be another step for data binning that is reducing effects of minor observation errors. That is, it can justify filling missing value with zero. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values for string data column\n",
      "Filling missing values for non-string data (numeric, categogircal) column\n"
     ]
    }
   ],
   "source": [
    "print(\"Filling missing values for string data column\")\n",
    "train['FireplaceQu'] = train['FireplaceQu'].fillna('None')\n",
    "train['GarageCond'] = train['GarageCond'].fillna('No Garage')\n",
    "train['GarageType'] = train['GarageType'].fillna('No Garage')\n",
    "train['GarageFinish'] = train['GarageFinish'].fillna('No Garage')\n",
    "train['GarageQual'] = train['GarageQual'].fillna('No Garage')\n",
    "train['BsmtCond'] = train['BsmtCond'].fillna('No Basement')\n",
    "train['BsmtFinType1'] = train['BsmtFinType1'].fillna('No Basement')\n",
    "train['BsmtQual'] = train['BsmtQual'].fillna('No Basement')\n",
    "train['BsmtFinType2'] = train['BsmtFinType2'].fillna('No Basement')\n",
    "train['BsmtExposure'] = train['BsmtExposure'].fillna('No Basement')\n",
    "train[\"Functional\"] = train[\"Functional\"].fillna(\"Typ\")\n",
    "train['MasVnrType'] = train['MasVnrType'].fillna('None')\n",
    "\n",
    "test['FireplaceQu'] = test['FireplaceQu'].fillna('None')\n",
    "test['GarageCond'] = test['GarageCond'].fillna('No Garage')\n",
    "test['GarageType'] = test['GarageType'].fillna('No Garage')\n",
    "test['GarageFinish'] = test['GarageFinish'].fillna('No Garage')\n",
    "test['GarageQual'] = test['GarageQual'].fillna('No Garage')\n",
    "test['BsmtCond'] = test['BsmtCond'].fillna('No Basement')\n",
    "test['BsmtFinType1'] = test['BsmtFinType1'].fillna('No Basement')\n",
    "test['BsmtQual'] = test['BsmtQual'].fillna('No Basement')\n",
    "test['BsmtFinType2'] = test['BsmtFinType2'].fillna('No Basement')\n",
    "test['BsmtExposure'] = test['BsmtExposure'].fillna('No Basement')\n",
    "test[\"Functional\"] = test[\"Functional\"].fillna(\"Typ\")\n",
    "test['MasVnrType'] = test['MasVnrType'].fillna('None')\n",
    "\n",
    "print(\"Filling missing values for non-string data (numeric, categogircal) column\")\n",
    "train['BsmtHalfBath'] = train['BsmtHalfBath'].fillna(0)\n",
    "train['BsmtFullBath'] = train['BsmtFullBath'].fillna(0)\n",
    "train['GarageCars'] = train['GarageCars'].fillna(0)\n",
    "train['GarageArea'] = train['GarageArea'].fillna(0)\n",
    "train['TotalBsmtSF'] = train['TotalBsmtSF'].fillna(0)\n",
    "train['BsmtFinSF1'] = train['BsmtFinSF1'].fillna(0)\n",
    "train['BsmtFinSF1'] = train['BsmtFinSF1'].fillna(0)\n",
    "train['BsmtUnfSF'] = train['BsmtUnfSF'].fillna(0)\n",
    "train['MSZoning'] = train['MSZoning'].fillna(train['MSZoning'].mode()[0]) #RL\n",
    "train['KitchenQual'] = train['KitchenQual'].fillna(train['KitchenQual'].mode()[0]) #TA\n",
    "train['Exterior1st'] = train['Exterior1st'].fillna(train['Exterior1st'].mode()[0])\n",
    "train['Exterior2nd'] = train['Exterior2nd'].fillna(train['Exterior2nd'].mode()[0])\n",
    "train['SaleType'] = train['SaleType'].fillna(train['SaleType'].mode()[0])\n",
    "train['Electrical'] = train['Electrical'].fillna(train['Electrical'].mode()[0])\n",
    "train['MasVnrArea'] = train['MasVnrArea'].fillna(0)\n",
    "train['GarageYrBlt'] = train['GarageYrBlt'].fillna('0')\n",
    "\n",
    "test['BsmtHalfBath'] = test['BsmtHalfBath'].fillna(0)\n",
    "test['BsmtFullBath'] = test['BsmtFullBath'].fillna(0)\n",
    "test['GarageCars'] = test['GarageCars'].fillna(0)\n",
    "test['GarageArea'] = test['GarageArea'].fillna(0)\n",
    "test['TotalBsmtSF'] = test['TotalBsmtSF'].fillna(0)\n",
    "test['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(0)\n",
    "test['BsmtFinSF1'] = test['BsmtFinSF1'].fillna(0)\n",
    "test['BsmtUnfSF'] = test['BsmtUnfSF'].fillna(0)\n",
    "test['MSZoning'] = test['MSZoning'].fillna(train['MSZoning'].mode()[0]) #RL\n",
    "test['KitchenQual'] = test['KitchenQual'].fillna(train['KitchenQual'].mode()[0]) #TA\n",
    "test['Exterior1st'] = test['Exterior1st'].fillna(train['Exterior1st'].mode()[0])\n",
    "test['Exterior2nd'] = test['Exterior2nd'].fillna(train['Exterior2nd'].mode()[0])\n",
    "test['SaleType'] = test['SaleType'].fillna(train['SaleType'].mode()[0])\n",
    "test['Electrical'] = test['Electrical'].fillna(train['Electrical'].mode()[0])\n",
    "test['MasVnrArea'] = test['MasVnrArea'].fillna(0)\n",
    "test['GarageYrBlt'] = test['GarageYrBlt'].fillna('0')\n",
    "\n",
    "# Missing values re-check after filling data\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum() / train.isnull().count() * 100).sort_values(ascending=False)\n",
    "assert percent[0] <= 0.00, \"There is still %r missing values\" % (total[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Value Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Categorical values need to be transformed to string data type since comparison by numeric value can mislead prediction.\n",
    "2) Convert MSSubClass, OverallCond, YrSold, and MoSold as String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MSSubClass'] = train['MSSubClass'].apply(str)\n",
    "train['OverallCond'] = train['OverallCond'].astype(str)\n",
    "train['YrSold'] = train['YrSold'].astype(str)\n",
    "train['MoSold'] = train['MoSold'].astype(str)\n",
    "\n",
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Since SalePrice does not have zero value, log instead of log1p will be applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non zero sales price number:1460, size of sales price:1460\n"
     ]
    }
   ],
   "source": [
    "print(\"Non zero sales price number:{}, size of sales price:{}\"\n",
    "      .format(np.count_nonzero(train['SalePrice']), len(train['SalePrice'])))\n",
    "y = np.log(train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to transform numeric features\n",
    "* List all the features that needs Log transformation (including SalePrice output variable if needed)\n",
    "* Perform log-transformation and add into the dataframe as new columns\n",
    "* Normalize numeric features using SandardScaler?\n",
    "\n",
    "* How to transform categorical features?\n",
    "- using pandas getDummies?\n",
    "- using sklearn ordinal encoding or one-hot encoding? How about simply changing numerical to string?\n",
    "- some other methods?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hstogram and normal probability plot\n",
    "sns.distplot(train['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformed histogram and normal probability plot\n",
    "sns.distplot(np.log(train['SalePrice']), fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(np.log(train['SalePrice']), plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, all the above analysis should result into these final data frames\n",
    "\n",
    "X_train: contains all relevant features and their values (transformed if relevant)  \n",
    "\n",
    "Y_train: (transformed) SalePrice column  \n",
    "\n",
    "X_test: contains tranformed dataframe from train data set (same tranformation as that was done for train)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 fields whose missing data portion is larger than 50%. Missing data will be cleaned up in the follow-up section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = train.select_dtypes(exclude = ['object']).columns\n",
    "categorical_features = train.select_dtypes(include = [\"object\"]).columns\n",
    "\n",
    "# find discrete features within numerical features\n",
    "discrete_features = []\n",
    "print(\"Discrete numerical features:\")\n",
    "for var in numerical_features:\n",
    "    if len(train[var].unique())<20:\n",
    "        print(var, ' values: ', train[var].unique())\n",
    "        discrete_features.append(var)\n",
    "        \n",
    "print('**There are {} categorical variables; {} discrete variables out of {} total numeric vars**'.format(len(discrete_features), len(discrete_features), len(numerical_features)))\n",
    "\n",
    "numerical_features, categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev =  train.sample(frac=1).head(100)\n",
    "#train_data = train[101:][:]\n",
    "#train_data.info()\n",
    "#print(\"shape of train data: {}\".format(train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "num_melt = pd.melt(train, id_vars=['SalePrice'], \n",
    "                   value_vars = [f for f in numerical_features if f not in ['Id', 'SalePrice']])\n",
    "g = sns.FacetGrid(data=num_melt, col=\"variable\", col_wrap=4, sharex=False, sharey=False)\n",
    "g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and plan model tuning for these types of features\n",
    "* near normal features\n",
    "* bi modal features\n",
    "* multi-modal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_features = ['LotArea', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'GarageArea']\n",
    "\n",
    "for f in log_features:\n",
    "    train[f + '_Log'] = np.log1p(train[f])\n",
    "    test[f + '_Log'] = np.log1p(test[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.drop(log_features, axis=1).corr()\n",
    "corr = corr.SalePrice\n",
    "m = pd.DataFrame(pd.concat([DataFrame(corr.index, columns=['feature']), pd.DataFrame(corr.values, columns=['corr'])], axis=1))\n",
    "plt.figure(figsize=(6, 30))\n",
    "sns.barplot(data=m.sort_values(by='corr', ascending=False), x='corr', y='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[(train.LotShape == 'IR2') & (train.SalePrice > 300000)].index, inplace=True)\n",
    "train.drop(train[(train.LandContour == 'Bnk') & (train.SalePrice > 300000)].index, inplace=True)\n",
    "train.drop(train[(train.PavedDrive == 'P') & (train.SalePrice > 200000)].index, inplace=True)\n",
    "train.drop(train[(train.MSZoning == 'RL') & (train.SalePrice > 500000)].index, inplace=True)\n",
    "train.drop(train[(train.KitchenQual == 'TA') & (train.SalePrice > 300000)].index, inplace=True)\n",
    "train.drop(train[(train.MSZoning == 'RM') & (train.SalePrice > 350000)].index, inplace=True)\n",
    "train.drop(train[(train.LotConfig == 'Corner') & (train.SalePrice > 410000)].index, inplace=True)\n",
    "train.drop(train[(train.Functional == 'Min2') & (train.SalePrice > 300000)].index, inplace=True)\n",
    "train.drop(train[(train.HouseStyle == '1.5Fin') & (train.SalePrice > 400000)].index, inplace=True)\n",
    "train.drop(train[(train.LandContour == 'Low') & (train.SalePrice > 350000)].index, inplace=True)\n",
    "\n",
    "missing_idx = [977, 1278, 234, 973, 1243, 650, 936, 529, 1379]\n",
    "train.loc[missing_idx, ['MasVnrType', 'MasVnrArea', 'Electrical']]\n",
    "\n",
    "train.drop(missing_idx, inplace=True)\n",
    "\n",
    "\n",
    "train.drop(train[train.LotArea > 100000].index, inplace=True)\n",
    "train.drop(train[train.MasVnrArea > 1500].index, inplace=True)\n",
    "train.drop(train[train.BsmtFinSF1 > 4000].index, inplace=True)\n",
    "train.drop(train[train.BsmtFinSF2 > 1300].index, inplace=True)\n",
    "train.drop(train[train.TotalBsmtSF > 4000].index, inplace=True)\n",
    "train.drop(train[train['1stFlrSF'] > 4000].index, inplace=True)\n",
    "train.drop(train[train.LowQualFinSF == 572].index, inplace=True)\n",
    "train.drop(train[train.GrLivArea > 4000].index, inplace=True)\n",
    "train.drop(train[train.OpenPorchSF == 523].index, inplace=True)\n",
    "train.drop(train[train.MiscVal > 5000].index, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# assign default values for NaN\n",
    "test.loc[test.MasVnrType.isnull(), 'MasVnrType'] = 'None'\n",
    "test.loc[test.MasVnrArea.isnull(), 'MasVnrArea'] = 0.0\n",
    "test.loc[test.MSZoning.isnull(), 'MSZoning'] = 'RL'\n",
    "test.loc[test.BsmtFullBath.isnull(), 'BsmtFullBath'] = 0\n",
    "test.loc[test.BsmtHalfBath.isnull(), 'BsmtHalfBath'] = 0\n",
    "test.loc[test.Functional.isnull(), 'Functional'] = 'Typ'\n",
    "test.loc[test.Utilities.isnull(), 'Utilities'] = 'AllPub'\n",
    "test.loc[test.BsmtFinSF2.isnull(), 'BsmtFinSF2'] = 0\n",
    "test.loc[test.SaleType.isnull(), 'SaleType'] = 'WD'\n",
    "test.loc[test.TotalBsmtSF.isnull(), 'TotalBsmtSF'] = 0\n",
    "test.loc[test.KitchenQual.isnull(), 'KitchenQual'] = 'TA'\n",
    "test.loc[test.BsmtUnfSF.isnull(), 'BsmtUnfSF'] = 0\n",
    "test.loc[test.Exterior1st.isnull(), 'Exterior1st'] = 'VinylSd'\n",
    "test.loc[test.GarageArea_Log.isnull(), 'GarageArea_Log'] = 0.0\n",
    "test.loc[test.BsmtFinSF1.isnull(), 'BsmtFinSF1'] = 0\n",
    "test.loc[test.TotalBsmtSF_Log.isnull(), 'TotalBsmtSF_Log'] = 0.0\n",
    "test.loc[test.GarageCars.isnull(), 'GarageCars'] = 2\n",
    "test.loc[test.GarageArea.isnull(), 'GarageArea'] = 0\n",
    "test.loc[test.Exterior2nd.isnull(), 'Exterior2nd'] = 'VinylSd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we plan to perform:\n",
    "* Feature Engineering\n",
    "* Dimentionality reduction\n",
    "* Building and tuning home prices prediction models\n",
    "\n",
    "\n",
    "From 79 available features (input variables), we will find statistically and practically significant variables for modeling. We also will try to watch out for collinearity and spurious relationships.  \n",
    "\n",
    "We plan to start with LinearRegression model because of the predictive nature of the problem. We will also try other supervised learning models such as Random Forest and Gradient Boosting Tree if they increase accuracy.\n",
    "\n",
    "We will be working on two broad sets of algorithms:\n",
    "1. Linear Models\n",
    "2. Non Linear relationships using Random Forests\n",
    "\n",
    "#### Linear Models\n",
    "For linear models, we will try and test with the regular OLS model, and the regularized linear models of Ridge Regression, Least Absolute Shrinkage and Selection Operator (LASSO), and Elastic Net. \n",
    "\n",
    "For model tuning, Sklearn's grid search with CV function will be used to find the optimal hyper-parameter values.\n",
    "\n",
    "To assess the predictive performance of regression models, we can compute the mean sum of squared errors and the related summary metric. Furthermore, we can also use graphical approach of residual plots to diagnose problems of linear regression models\n",
    "\n",
    "We can apply regularization to our regression models to reduce the model complexity and avoid overfitting.\n",
    "\n",
    "#### Non Linear relationships using Random Forests\n",
    "For the decision tree algorithm, we will subdivide the input space into smaller regions so that it's more manageable. As Decision tree algorithm does not require any transformation of the features for nonlinear data, there will not be any feature transformation in this section. Since random forests are less sensitive to outliers in the dataset we are assuming at this point that it will not require much parameter tuning. The only parameter that will require experimenting might be number of trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = list(train.select_dtypes(include=np.number).columns)\n",
    "print(numerics)\n",
    "categorical = list(train.select_dtypes(exclude=np.number).columns)\n",
    "print(categorical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = train.drop([f for f in categorical_features] + log_features + ['SalePrice'], axis=1)\n",
    "X_test = test.drop([f for f in categorical_features] + log_features , axis=1)\n",
    "\n",
    "\n",
    "X_all_categorical = pd.get_dummies(train[categorical_features],drop_first=True)\n",
    "X_test_categorical = pd.get_dummies(test[categorical_features],drop_first=True)\n",
    "\n",
    "print(\"{}, {}\".format(X_all_categorical.shape,X_test_categorical.shape))\n",
    "\n",
    "\n",
    "\n",
    "std = StandardScaler()\n",
    "X_all[:] = std.fit_transform(X_all)\n",
    "X_test[:] = std.fit_transform(X_test)\n",
    "\n",
    "y_all = train.SalePrice\n",
    "#y_all[:] = np.log1p(y_all)\n",
    "\n",
    "\n",
    "# TODO: Perform ordinal encoding of categorical_features\n",
    "all_features_train = [X_all, X_all_categorical]\n",
    "X_all = pd.concat(all_features_train, axis=1)\n",
    "all_features_test = [X_test, X_test_categorical]\n",
    "X_test = pd.concat(all_features_test, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# split 80/20 train-dev\n",
    "X_train_data, X_dev_data, y_train_data, y_dev_data = train_test_split(X_all,\n",
    "                                                    y_all,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "features = list(X_train_data)\n",
    "\n",
    "y_train_data_log = np.log(y_train_data)\n",
    "y_dev_data_log = np.log(y_dev_data)\n",
    "#y_all.shape, X_all.shape, X_test.shape\n",
    "#print(y_dev_data)\n",
    "X_train_data.shape, X_dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "res = defaultdict(dict)\n",
    "def benchmark(model, name=None):\n",
    "    if not name:\n",
    "        name = model.__class__.__name__\n",
    "    t0 = time.clock()\n",
    "    model.fit(X_train_data, y_train_data_log)\n",
    "    res[name]['train_time'] = time.clock() - t0\n",
    "    t0 = time.clock()\n",
    "    pred = model.predict(X_dev_data)\n",
    "    res[name]['test_time'] = time.clock() - t0\n",
    "    res[name]['rmse'] = np.sqrt(mean_squared_error(y_dev_data_log, pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(LinearRegression())\n",
    "benchmark(Ridge(alpha=5.2))\n",
    "benchmark(ElasticNet(alpha=0.01))\n",
    "est = benchmark(GradientBoostingRegressor(learning_rate=0.1, n_estimators=200))\n",
    "benchmark(RandomForestRegressor(n_estimators=30, max_depth=10))\n",
    "res_df = pd.DataFrame(data=res).T\n",
    "res_df[['train_time', 'test_time', 'rmse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (11,7)\n",
    "type(est.feature_importances_)\n",
    "fx_imp = pd.Series(est.feature_importances_, index=features)\n",
    "fx_imp /= fx_imp.max()  # normalize\n",
    "#fx_imp.sort()\n",
    "fx_imp.nlargest(20).plot(kind='barh', figsize=FIGSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial dependence\n",
    "\n",
    "  * Relationship between the response and a set of features, marginalizing over all other features\n",
    "  * Intuitively: expected response as a function of the features we conditioned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "features = ['MasVnrArea', 'MoSold', 'MiscVal', 'FullBath', 'SaleCondition_Family','OpenPorchSF', '2ndFlrSF', 'EnclosedPorch',\n",
    "           'WoodDeckSF','TotalBsmtSF_Log']\n",
    "fig, axs = plot_partial_dependence(est, X_train_data, features, feature_names=features, \n",
    "                                   n_cols=6, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Key Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will present our key findings in terms of key predictor variables and their parameter values. We will also summary the modeling process and learning from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
